[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言学习笔记",
    "section": "",
    "text": "笔记集\n本笔记集整理了R语言在数据分析和可视化、统计建模、机器学习等方面的学习笔记，准备记录tidyverse、tidymodels、mlr3、R6、gt等R包的使用方法和实例。\n笔记集使用Quarto编写，并使用GitHub Pages托管，可以通过https://caowz254.github.io/ln-r/在线阅读和标注。代码部分除了参考书籍和官方文档，也使用了GitHub Copilot的AI自动补全功能，以提高编写效率。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "R语言学习笔记",
    "section": "Quarto",
    "text": "Quarto\nQuarto是R Markdown的扩展，支持多种输出格式，包括HTML、PDF、Word等。Render的核心是一个R包，它提供了一些新的语法和功能，以便更好地支持多种输出格式。Quarto的官方文档是https://quarto.org/docs/guide/。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "index.html#github-pages",
    "href": "index.html#github-pages",
    "title": "R语言学习笔记",
    "section": "GitHub Pages",
    "text": "GitHub Pages\nGitHub Pages是GitHub提供的静态网页托管服务，笔记集在本地撰写和修改，提交到GitHub后，自动构建和发布网页。Quarto有一套完整的功能，可以基本实现网页自动化部署。\n\n\n\n\n\n\n重要\n\n\n\n部署网页流程，可在RStudio terminal操作：\nquarto render # 本地完整渲染\ngit status # 检查修改情况，每次git后都要检查一下\ngit add . # 添加全部文件到暂存区，可跳过\ngit commit -a # 将暂存区文件提交到本地仓库\ngit push --all # 将本地仓库文件推送到远程仓库",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html",
    "href": "chapters/tidymodels-基础.html",
    "title": "2  tidymodels-基础",
    "section": "",
    "text": "2.1 建模基础\n---\ntitle: 建模的分类\n---\nflowchart LR\nA[模型] --- B[描述性模型]\nA --- C[推理模型]\nA --- D[预测模型]\nD --- E[无监督模型]\nD --- F[监督模型]\nE --- G[\"主成分分析(PCA)\"]\nE --- H[聚类]\nE --- I[自动编码器]\nF --- J[回归]\nF --- K[神经网络]\n---\ntitle: 模型建模的一般步骤\n---\nflowchart LR\nA[导入数据] --&gt; B[\"清洗数据(tidy)\"] ---&gt; C[\"探索性数据分析(EDA)\"] --&gt; D[特征工程] --&gt; E[建模与优化] --&gt; F[评估] --&gt; G[部署]\nF -.-&gt; C",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#练习数据和探索性数据分析",
    "href": "chapters/tidymodels-基础.html#练习数据和探索性数据分析",
    "title": "2  tidymodels-基础",
    "section": "2.2 练习数据和探索性数据分析",
    "text": "2.2 练习数据和探索性数据分析\n练习数据使用的是modeldata包中的ames数据集。数据集包括：\n\n房屋特征house characteristics，如bedrooms, garage, fireplace, pool, porch等；\n区位location；\n地块信息lot information，如zoning, shape, size等；\n条件和质量评级ratings of condition and quality；\n成交价格sale price。\n\n\n\n代码\ndata(ames)\ndim(ames)\n\n\n[1] 2930   74\n\n\n\n2.2.1 探索性数据分析-探索住宅特点\n首先关注房屋的最终销售价格（美元）。使用直方图来查看销售价格的分布情况，如 图 2.1 所示。\n\n\n代码\ntidymodels_prefer() # 用于处理包之间的函数冲突，不会输出结果\n\names |&gt;\n  ggplot(aes(x = Sale_Price)) +\n  geom_histogram(bins = 50, col = \"white\") +\n  theme_bw() -&gt; fig_0201\n\n\n\n\n代码\nfig_0201\n\n\n\n\n\n\n\n\n图 2.1: 销售价格（美元）\n\n\n\n\n\n作图发现数据是偏态的，可以使用对数变换来处理。这种转换的优点是，不会预测出负销售价格的房屋，而且预测昂贵房屋的误差也不会对模型产生过大的影响。另外，对数变换还可以稳定方差，使得模型更容易拟合。结果如 图 2.2 所示。\n\n\n代码\nfig_0201 +\n  scale_x_log10() -&gt; fig_0202\n\n\n\n\n代码\nfig_0202\n\n\n\n\n\n\n\n\n图 2.2: 对数变换后的销售价格（美元）\n\n\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n对数转换结果的主要缺点涉及到对模型结果的解释。在对数变换后，模型的系数不再是直接解释的，而是对数解释。这意味着，模型的系数是对数销售价格的变化，而不是销售价格的变化。这种情况下，需要小心解释模型的结果。\n\n\n对数转换的结果相对较好，因此可以使用对数转换后的销售价格作为目标变量。\n\n\n代码\names |&gt;\n  mutate(Sale_Price = log10(Sale_Price)) -&gt; ames",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#数据分割",
    "href": "chapters/tidymodels-基础.html#数据分割",
    "title": "2  tidymodels-基础",
    "section": "2.3 数据分割",
    "text": "2.3 数据分割\n一般会将数据集分为训练集和测试集。训练集用于拟合模型，测试集用于评估模型的性能。\n测试集只能使用一次，否则就会成为建模过程的一部分。这样会导致模型在测试集上的性能过于乐观，无法真实地评估模型的性能。\n\n2.3.1 简单随机抽样\n在tidymodels中，可以使用initial_split()函数来分割数据集。默认情况下，initial_split()函数会将数据集分为80%的训练集和20%的测试集。\n\n\n代码\nset.seed(123)\n\names_split &lt;- initial_split(ames, prop = 0.8)\n\names_split\n\n\n&lt;Training/Testing/Total&gt;\n&lt;2344/586/2930&gt;\n\n\names_split是一个rsplit对象，仅包含分区信息，可以使用training()和testing()函数来提取训练集和测试集。\n\n\n代码\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\ndim(ames_train)\n\n\n[1] 2344   74\n\n\n\n\n2.3.2 分层抽样\n在某些情况下，需要使用分层抽样。例如，如果数据集中有一个重要的类别变量，那么就需要使用分层抽样来确保训练集和测试集中都包含这个类别变量的各个水平。\n可以人为地将结果数据四等分，然后分别进行四次分层抽样，这样可以保持训练集和测试集的分布一致。\n\n\n代码\names |&gt;\n  pull(Sale_Price) |&gt; # 提取销售价格\n  density(n = 2^10) |&gt; # 生成密度估计\n  tidy() -&gt; sale_dens # 将结果转换为数据框\n\ntibble(prob = (1:3)/4, value = quantile(ames$Sale_Price, probs = prob)) |&gt; # 计算四分位数\n  mutate(y = approx(sale_dens$x, sale_dens$y, xout = value)$y) -&gt; quartiles # 计算四分位数的密度值\n\names |&gt;\n  ggplot(aes(x = Sale_Price)) +\n  geom_line(stat = \"density\") +\n  geom_segment(data = quartiles,\n               aes(x = value, xend = value, y = 0, yend = y),\n               lty = 2) +\n  labs(x = \"Sale Price (log-10 USD)\", y = NULL) +\n  theme_bw() -&gt; fig_0203\nfig_0203\n\n\n\n\n\n\n\n\n图 2.3: 房屋销售价格分布(log)，虚线代表四分位数\n\n\n\n\n\n销售价格的分布呈右偏态，廉价房屋的比例更大。因此，可以使用分层抽样来确保训练集和测试集中都包含廉价房屋。可以使用strata参数来指定分层变量。\n\n\n代码\nset.seed(123)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\ndim(ames_train)\n\n\n[1] 2342   74\n\n\n\n\n\n\n\n\n注意\n\n\n\n只能使用单列作为分层变量，不能使用多列。\n\n\n\n\n2.3.3 交叉验证-验证集的分割\n交叉验证通常用于解决模型过拟合的问题。为此，可以把数据集分为训练集、测试集和验证集，其中验证集用于调整模型的超参数。可以用initial_vadilation_split()函数来实现。\n\n\n代码\nset.seed(123)\names_val_split &lt;- initial_validation_split(ames, prop = c(0.6, 0.2))\n\names_val_split\n\n\n&lt;Training/Validation/Testing/Total&gt;\n&lt;1758/586/586/2930&gt;\n\n\n代码\names_val_train &lt;- training(ames_val_split)\names_val_test  &lt;- testing(ames_val_split)\names_val_val   &lt;- validation(ames_val_split)",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型拟合-以线性回归为例",
    "href": "chapters/tidymodels-基础.html#模型拟合-以线性回归为例",
    "title": "2  tidymodels-基础",
    "section": "2.4 模型拟合-以线性回归为例",
    "text": "2.4 模型拟合-以线性回归为例\n对于一些相对简单的模型，可以使用parsnip包中的fit和predict函数来拟合和预测。parsnip包提供了统一的接口，可以使用相同的函数来拟合不同的模型。\n使用parsnip中的linear_reg()函数指定模型类型，set_engine()函数指定模型引擎，这里的引擎一般指的是具体建模使用的软件包名称。确定模型后，可以使用fit()函数或fit_xy()函数来拟合模型。以三种常用的线性回归模型为例。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nModel fit template:\nstats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())\n\n\n代码\nlinear_reg(penalty = 1) |&gt; # panalty是glmnet的特有参数\n  set_engine(\"glmnet\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    family = \"gaussian\")\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"stan\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\nModel fit template:\nrstanarm::stan_glm(formula = missing_arg(), data = missing_arg(), \n    weights = missing_arg(), family = stats::gaussian, refresh = 0)\n\n\n\ntranslate()函数可以提供模型转换的详细参数信息。\nmissing_arg()是占位符，表示数据未提供。\n\n以经度和纬度为自变量，销售价格为因变量，拟合线性回归模型。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") -&gt; lm_model\n\nlm_model |&gt;\n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train) -&gt; lm_form_fit\n\nlm_model |&gt;\n  fit_xy(x = ames_train |&gt;\n           select(Longitude, Latitude),\n         y = ames_train |&gt;\n           pull(Sale_Price)\n  ) -&gt; lm_xy_fit\n\nlm_form_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nlm_xy_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#提取模型结果",
    "href": "chapters/tidymodels-基础.html#提取模型结果",
    "title": "2  tidymodels-基础",
    "section": "2.5 提取模型结果",
    "text": "2.5 提取模型结果\nlm_form_fit和lm_xy_fit是parsnip模型对象，拟合模型储存在fit属性中。可以使用extract_fit_engine()函数提取拟合模型。\n\n\n代码\nlm_form_fit |&gt;\n  tidy() # 最简单的提取模型系数的方法（提取为tibble）\n\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  -300.      14.6       -20.6 1.02e-86\n2 Longitude      -2.01     0.130     -15.5 8.13e-52\n3 Latitude        2.78     0.182      15.3 1.64e-50\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt; # 提取模型\n  vcov() # 提取模型的协方差矩阵\n\n\n            (Intercept)     Longitude      Latitude\n(Intercept)  212.620590  1.6113032179 -1.4686377363\nLongitude      1.611303  0.0168165968 -0.0008694728\nLatitude      -1.468638 -0.0008694728  0.0330018995\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt;\n  summary() |&gt; # 提取模型的摘要信息\n  coef() # 提取模型的系数\n\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -300.250929 14.5815154 -20.59120 1.022609e-86\nLongitude     -2.013413  0.1296788 -15.52615 8.126177e-52\nLatitude       2.781713  0.1816642  15.31239 1.639312e-50\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt;\n  gtsummary::tbl_regression() # 生成模型摘要信息\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nLongitude\n-2.0\n-2.3, -1.8\n&lt;0.001\n\n\nLatitude\n2.8\n2.4, 3.1\n&lt;0.001\n\n\n\n1 CI = Confidence Interval",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型预测",
    "href": "chapters/tidymodels-基础.html#模型预测",
    "title": "2  tidymodels-基础",
    "section": "2.6 模型预测",
    "text": "2.6 模型预测\n使用predict()函数进行预测。\n\n\n代码\names_test |&gt;\n  slice(1:5) -&gt; ames_test_small # 选择前五行数据\n\npredict(lm_form_fit, new_data = ames_test_small) # 预测结果\n\n\n# A tibble: 5 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.22\n2  5.22\n3  5.28\n4  5.24\n5  5.31\n\n\n代码\names_test_small |&gt;\n  select(Sale_Price) |&gt; # 真实值\n  bind_cols(predict(lm_form_fit, ames_test_small)) |&gt; # 预测值\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) # 预测区间\n\n\n# A tibble: 5 × 4\n  Sale_Price .pred .pred_lower .pred_upper\n       &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1       5.02  5.22        4.91        5.54\n2       5.24  5.22        4.91        5.54\n3       5.28  5.28        4.97        5.60\n4       5.06  5.24        4.92        5.56\n5       5.60  5.31        5.00        5.63\n\n\n以决策树为例，对数据进行建模\n\n\n代码\ndecision_tree(min_n = 2) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\") -&gt; tree_model\n\ntree_model |&gt;\n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train) -&gt; tree_fit\n\names_test_small |&gt;\n  select(Sale_Price) |&gt; # 真实值\n  bind_cols(predict(tree_fit, ames_test_small)) # 预测值\n\n\n# A tibble: 5 × 2\n  Sale_Price .pred\n       &lt;dbl&gt; &lt;dbl&gt;\n1       5.02  5.15\n2       5.24  5.15\n3       5.28  5.31\n4       5.06  5.15\n5       5.60  5.52\n\n\n\n\n\n\n\n\n重要\n\n\n\n可以在https://www.tidymodels.org/find/找所有可用的模型。\nparsnip_addin()函数可以在RStudio中搜索模型。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#workflow",
    "href": "chapters/tidymodels-基础.html#workflow",
    "title": "2  tidymodels-基础",
    "section": "2.7 workflow",
    "text": "2.7 workflow\n\n2.7.1 创建workflow对象\n使用lm_model来创建workflow对象，workflow对象可以将数据预处理和模型拟合整合在一起。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") -&gt; lm_workflow\n\n\n\n\n代码\nworkflow() |&gt;\n  add_model(lm_model) -&gt; lm_workflow\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: None\nModel: linear_reg()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\n\n\n\n注释\n\n\n\nlm_workflow中，Preprocessor为空，代表没有数据预处理。\n\n\n\n\n2.7.2 添加预处理器\n使用add_formula函数输入标准公式作为预处理器：\n\n\n代码\nlm_workflow |&gt;\n  add_formula(Sale_Price ~ Longitude + Latitude) -&gt; lm_workflow\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nworkflow对象可以使用fit()函数拟合模型，使用predict()函数进行预测。\n\n\n代码\nlm_workflow |&gt;\n  fit(data = ames_train) -&gt; lm_fit\n\nlm_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nlm_fit |&gt;\n  predict(new_data = ames_test |&gt;\n            slice(1:3)) # 预测\n\n\n# A tibble: 3 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.22\n2  5.22\n3  5.28\n\n\n可以使用update_formula函数更新预处理器：\n\n\n代码\nlm_fit |&gt;\n  update_formula(Sale_Price ~ Longitude)\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n2.7.3 添加变量\n使用add_variables函数添加变量。函数有两个参数：outcomes和predictors。支持使用c()函数添加多个变量。\n\n\n代码\nlm_workflow |&gt;\n  remove_formula() |&gt;\n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude)) -&gt; lm_workflow # 和上面的add_formula等价\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n拟合模型：\n\n\n代码\nfit(lm_workflow, data = ames_train) # 拟合模型\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n\n\n2.7.4 为workflow使用公式\n\n2.7.4.1 基于树的模型\n使用Orthodont数据集，拟合一个受试者具有随机效应的回归模型。\n在workflow中，使用add_variables()函数添加变量，使用add_model()函数添加模型。\n\n\n代码\nlibrary(multilevelmod) # parsnip扩展包，主要用于多层次模型（混合效应模型、贝叶斯层次模型等）\n\ndata(Orthodont, package = \"nlme\")\n\nlinear_reg() |&gt;\n  set_engine(\"lmer\") -&gt; multilevel_spec # lmer是lme4包中的函数，用于拟合线性混合效应模型\n  \nworkflow() |&gt;\n  add_variables(outcome = distance, predictors = c(Sex, age, Subject)) |&gt; \n  add_model(multilevel_spec, \n            formula = distance ~ Sex + (age | Subject)) -&gt; multilevel_workflow # age | Subject表示age是Subject的随机效应\n\nmultilevel_workflow |&gt;\n  fit(data = Orthodont) -&gt; multilevel_fit\n\nmultilevel_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: distance\nPredictors: c(Sex, age, Subject)\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear mixed model fit by REML ['lmerMod']\nFormula: distance ~ Sex + (age | Subject)\n   Data: data\nREML criterion at convergence: 471.1635\nRandom effects:\n Groups   Name        Std.Dev. Corr \n Subject  (Intercept) 7.3912        \n          age         0.6943   -0.97\n Residual             1.3100        \nNumber of obs: 108, groups:  Subject, 27\nFixed Effects:\n(Intercept)    SexFemale  \n     24.517       -2.145  \n\n\n可以进一步使用survival包中的strata函数进行生存分析.\n\n\n代码\nlibrary(censored) # parsnip扩展包，主要用于删减回归和生存分析模型\n\nsurvival_reg() -&gt; parametric_spec\n\ndata(cancer, package = \"survival\")\n\nworkflow() |&gt;\n  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) |&gt;\n  add_model(parametric_spec, \n            formula = Surv(futime, fustat) ~ age + strata(rx)) -&gt; parametric_workflow\n\nparametric_workflow |&gt;\n  fit(data = ovarian) -&gt; parametric_fit\n\nparametric_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: survival_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: c(fustat, futime)\nPredictors: c(age, rx)\n\n── Model ───────────────────────────────────────────────────────────────────────\nCall:\nsurvival::survreg(formula = Surv(futime, fustat) ~ age + strata(rx), \n    data = data, model = TRUE)\n\nCoefficients:\n(Intercept)         age \n 12.8734120  -0.1033569 \n\nScale:\n     rx=1      rx=2 \n0.7695509 0.4703602 \n\nLoglik(model)= -89.4   Loglik(intercept only)= -97.1\n    Chisq= 15.36 on 1 degrees of freedom, p= 8.88e-05 \nn= 26 \n\n\n\n\n\n2.7.5 同时创建多个workflow\n做预测模型时，一般需要评估多个不同的模型。例如筛选预测因子。可以创建一组formula来罗列不同的预测因子组合。\n\n\n代码\nlist(\n  longitude = Sale_Price ~ Longitude,\n  latitude = Sale_Price ~ Latitude,\n  coords = Sale_Price ~ Longitude + Latitude,\n  neighborhood = Sale_Price ~ Neighborhood) -&gt; location\n\n\n使用workflow_set()函数创建一个workflow集合。\n\n\n代码\nworkflow_set(preproc = location, models = list(lm = lm_model)) -&gt; location_models\n\nlocation_models\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 longitude_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 latitude_lm     &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 coords_lm       &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 neighborhood_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n代码\nlocation_models$info[[1]] # 查看第一个workflow的信息\n\n\n# A tibble: 1 × 4\n  workflow   preproc model      comment\n  &lt;list&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n1 &lt;workflow&gt; formula linear_reg \"\"     \n\n\n代码\nextract_workflow(location_models, id = \"coords_lm\") # 提取一个workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n为每个formula创建fit对象：\n\n\n代码\nlocation_models |&gt;\n  mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train))) -&gt; location_models # 使用map函数对每个workflow进行拟合\n\nlocation_models\n\n\n# A workflow set/tibble: 4 × 5\n  wflow_id        info             option    result     fit       \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;     &lt;list&gt;    \n1 longitude_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n2 latitude_lm     &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n3 coords_lm       &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n4 neighborhood_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n\n\n代码\nlocation_models$fit[[1]] # 查看第一个workflow的拟合结果\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude  \n    -176.46        -1.94  \n\n\n\n\n2.7.6 评估测试集\n使用last_fit函数，可以把模型拟合到整个训练集，然后评估测试集。\n\n\n代码\nlast_fit(lm_workflow, ames_split) -&gt; final_lm_res # 用法：last_fit(模型, 数据分割)\n\nfinal_lm_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [2342/588]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\n代码\nfinal_lm_res |&gt;\n  extract_workflow() # 提取workflow\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nfinal_lm_res |&gt;\n  collect_metrics() # 收集模型评估指标\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.160 Preprocessor1_Model1\n2 rsq     standard       0.208 Preprocessor1_Model1\n\n\n代码\nfinal_lm_res |&gt;\n  collect_predictions() |&gt; # 收集预测结果\n  head()\n\n\n# A tibble: 6 × 5\n  id               .pred  .row Sale_Price .config             \n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;               \n1 train/test split  5.22     2       5.02 Preprocessor1_Model1\n2 train/test split  5.22     3       5.24 Preprocessor1_Model1\n3 train/test split  5.28     5       5.28 Preprocessor1_Model1\n4 train/test split  5.24    28       5.06 Preprocessor1_Model1\n5 train/test split  5.31    39       5.60 Preprocessor1_Model1\n6 train/test split  5.31    44       5.33 Preprocessor1_Model1",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#特征工程",
    "href": "chapters/tidymodels-基础.html#特征工程",
    "title": "2  tidymodels-基础",
    "section": "2.8 特征工程",
    "text": "2.8 特征工程\n特征工程指对预测值进行重新格式化，使其更容易被模型有效利用。特征工程的方法一般分为以下几种：\n\ndummy，哑变量，将分类变量分为多个哑变量（0-1变量）。\nzv， zero variance，删除方差为0的变量，也就是只有单一值的变量。\nimpute，估算，填补缺失值。\ndecorrelate，去相关，删除相关性较高的变量。一般使用PCA方法或者VIF方法。\nnormalize，标准化，将变量居中并缩放到单位方差。\ntransform，转换，将变量转换成更对称的分布。\n\n使用recipe包可以把不同的特征工程方法组合在一起，并应用到数据集上。\n\n2.8.1 创建特征工程\n从ames数据集中挑选以下预测因子：\n\nNeighborhood，分类变量，指房屋所在的社区，有29个水平。\nGr_Liv_Area，数值变量，指房屋的居住面积。\nYear_Built，数值变量，指房屋建造的年份。\nBldg_Type，分类变量，指房屋的类型，有5个水平，分别是OneFam，TwoFmCon，Duplex，Twnhs，TwnhsE。\n\n使用这些预测因子对Sale_Price进行预测，公式如下：\n\n\n代码\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, data = ames) # 由于Sale_Price取过对数，所以Gr_Liv_Area也取对数\n\n\n根据预测因子的性质和上述公式，使用recipe创建一个特征工程流程。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n       data = ames) |&gt; # 创建recipe对象，声明结果变量和预测因子\n  step_log(Gr_Liv_Area) |&gt; # 对Gr_Liv_Area取对数\n  step_dummy(all_nominal_predictors()) -&gt; simple_ames # 对分类变量创建哑变量\n\nsimple_ames\n\n\n\n\n\n\n\n\n提示\n\n\n\nall_nominal_predictors()函数用于选择所有的分类变量。\nall_numeric_predictors()函数用于选择所有的数值变量。\nall_predictors()函数用于选择所有的预测因子。\nall_outcomes()函数用于选择所有的结果变量。\nall_numeric()函数用于选择所有的数值变量。\n\n\n\n\n2.8.2 应用特征工程\n将特征工程simple_ames应用到workflowlm_workflow上。\n\n\n代码\nlm_workflow |&gt;\n  remove_variables() |&gt; # 删除所有的预测因子\n  remove_recipe() |&gt; # 删除所有的特征工程\n  add_recipe(simple_ames) -&gt; lm_workflow # 添加特征工程\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_log()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n代码\nfit(lm_workflow, ames_train) -&gt; lm_fit # 拟合模型\n\npredict(lm_fit, ames_test) |&gt; # 预测测试集\n  head()\n\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.17\n3  5.27\n4  5.08\n5  5.51\n6  5.44\n\n\n使用extract_*函数可以提取fit对象的不同信息，如模型参数、特征工程等。\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) # 提取特征工程，estimated = TRUE表示提取特征工程的估计值\n\nlm_fit |&gt;\n  extract_fit_parsnip() |&gt; # 提取模型参数\n  tidy() |&gt;\n  head()\n\n\n# A tibble: 6 × 5\n  term                       estimate std.error statistic   p.value\n  &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)                -0.682    0.228        -2.99 2.78e-  3\n2 Gr_Liv_Area                 0.271    0.00606      44.8  1.36e-315\n3 Year_Built                  0.00199  0.000115     17.3  6.19e- 63\n4 Neighborhood_College_Creek  0.0167   0.00807       2.06 3.91e-  2\n5 Neighborhood_Old_Town      -0.0357   0.00844      -4.22 2.50e-  5\n6 Neighborhood_Edwards       -0.0531   0.00755      -7.04 2.57e- 12\n\n\n\n\n2.8.3 其他特征工程示例\n\n2.8.3.1 定性变量的处理\n\n\n\n\n\n\n提示\n\n\n\nstep_unknown()函数用于将缺失值转化为专用因子水平。\nstep_novel()函数用于将未知的水平转化为新的水平。\nstep_other()函数用于将频率较低的多个水平合并为一个水平，频率阈值可以指定。\n\n\n上述函数可以用于处理定性变量的缺失值和未知水平，以及合并频率较低的水平，在此基础上，可以使用step_dummy()函数创建哑变量。\n\n\n2.8.3.2 交互项的处理\n交互项是指两个或多个变量的乘积，可以用于捕捉变量之间的关系。使用step_interact(~*:*)函数可以创建交互项。\n在ames数据集中，不同建筑类型的房屋可能与不同的居住面积存在交互，如 图 2.4 所示，可以使用交互项来捕捉这种关系。\n\n\n代码\nggplot(ames_train, aes(x = Gr_Liv_Area, y = 10^Sale_Price)) + \n  geom_point(alpha = .2) + \n  facet_wrap(~ Bldg_Type) + \n  geom_smooth(method = lm, formula = y ~ x, se = FALSE, color = \"lightblue\") + \n  scale_x_log10() + \n  scale_y_log10() + \n  labs(x = \"Gross Living Area\", y = \"Sale Price (USD)\")\n\n\n\n\n\n\n\n\n图 2.4: 五种不同类型建筑的总居住面积与销售价格的关系（log10变换后）\n\n\n\n\n\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) |&gt; # 创建recipe对象并声明结果变量和预测因子\n  step_log(Gr_Liv_Area, base = 10) |&gt; # 对Gr_Liv_Area取对数\n  step_other(Neighborhood, threshold = 0.01) |&gt; # 合并频率较低的水平\n  step_dummy(all_nominal_predictors()) |&gt; # 对分类变量创建哑变量\n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\")) -&gt; simple_ames # 创建交互项，其中:表示交互，可以使用+添加多组交互项\n\nsimple_ames\n\n\n\n\n\n\n\n\n警告\n\n\n\n一般来说，交互项需要在创建哑变量后才能创建，否则可能会报错。\n\n\n\n\n2.8.3.3 样条函数\n样条函数是一种非参数拟合方法，可以用于拟合非线性关系。使用step_ns()函数可以创建样条函数。\n在ames数据集中，经度和纬度可能与销售价格存在非线性关系，如 图 2.5 所示，可以使用样条函数来捕捉这种关系。\n\n\n代码\nlibrary(splines) # 样条函数\nlibrary(patchwork) # 绘图拼接\n\nplot_smoother &lt;- function(deg_free) { # 创建一个函数，用于绘制不同自由度的样条函数\n  ggplot(ames_train, aes(x = Latitude, y = 10^Sale_Price)) +  # 还原对数变换\n    geom_point(alpha = .2) +  # 添加散点图，alpha表示透明度\n    scale_y_log10() + # 对y轴进行对数变换\n    geom_smooth(\n      method = lm,\n      formula = y ~ ns(x, df = deg_free),\n      color = \"lightblue\",\n      se = FALSE\n    ) + # 添加样条函数，ns表示样条函数，df表示自由度\n    labs(title = paste(deg_free, \"Spline Terms\"),\n         y = \"Sale Price (USD)\")\n}\n\n( plot_smoother(2) + plot_smoother(5) ) / ( plot_smoother(20) + plot_smoother(100) ) # 绘制不同自由度的样条函数\n\n\n\n\n\n\n\n\n图 2.5: 销售价格与纬度的关系\n\n\n\n\n\n由 图 2.5 可以看出，自由度为5和20时，样条函数能较好地拟合数据，这里选择自由度为20的样条函数来捕捉纬度与销售价格的关系。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + Latitude,\n         data = ames_train) |&gt;\n  step_log(Gr_Liv_Area, base = 10) |&gt;\n  step_other(Neighborhood, threshold = 0.01) |&gt;\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\") ) |&gt;\n  step_ns(Latitude, deg_free = 20) # 创建样条函数，自由度为20\n\n\n\n\n2.8.3.4 特征提取（PCA）\n特征提取是指将多个原始特征合并为少数几个新特征，以减少数据维度。使用step_pca()函数可以进行主成分分析（PCA）。\nPCA是一种线性提取方法，其优点是每个主成分之间互不相关，因此可以减少多重共线性的影响。但是，PCA的缺点是提取的特征不易解释，而且新特征可能与结果无关。\n在ames数据集中，有几个预测因子测量了房产的面积，如地下室总面积Total_Bsmt_SF、一楼面积First_Flr_SF、总居住面积Gr_Liv_Area等。PCA 可以将这些潜在的冗余变量表示为一个较小的特征集。除了总居住面积外，这些预测因子的名称中都有后缀SF（表示平方英尺）。\nPCA假定所有预测因子的单位相同，因此在使用PCA之前，最好使用step_normalize()对这些预测因子进行标准化。\n\n\n代码\nstep_normalize(matches(\"(SF$)|(Gr_Liv)\")) |&gt;\nstep_pca(matches(\"(SF$)|(Gr_Liv)\"))\n\n\n\n\n\n\n\n\n提示\n\n\n\n特征提取的其他方法还包括独立成分分析（ICA），非负矩阵分解（NMF），多维缩放（MDS），均匀流形近似（UMAP），t-分布邻域嵌入（t-SNE）等。\n\n\n\n\n2.8.3.5 抽样技术\n类别不平衡问题是指分类问题中不同类别的样本数量差异较大。在这种情况下，模型可能会偏向于预测样本数量较多的类别，而忽略样本数量较少的类别。针对类别不平衡问题，可以采用子采样技术，它通常不会提高整体性能，但可以生成表现更好的预测类概率分布。子采样技术分类如下：\n\n下抽样(Downsampling)：保留少数类样本，对多数类样本进行随机抽样，以平衡频率。\n扩大抽样(Upsampling)：合成新的少数类样本，或直接复制少数类样本，以平衡频率。\nHybrid：结合上述两种方法。\n\n在themis包中，step_downsample()和step_upsample()函数可以实现下抽样和扩大抽样。\n\n\n\n\n\n\n提示\n\n\n\nstep_filter()函数可以用于删除不需要的样本，如异常值、缺失值等。\nstep_sample()函数可以用于随机抽样。\nstep_slice()函数可以用于分割数据集。\nstep_arrange()函数可以用于排序数据集。\n\n\n\n\n2.8.3.6 一般变换\n一般变换是指对数据进行一般性的变换，如对数变换、幂变换、指数变换等。在recipes包中，step_log()、step_sqrt()、step_YeoJohnson()、step_boxcox()等函数可以实现对数变换、平方根变换、Yeo-Johnson变换、Box-Cox变换等。step_mutate()函数可以利用已有变量计算并创建新的变量。\n\n\n\n\n\n\n警告\n\n\n\n进行一般变换是，需要格外注意避免数据泄露。转换应该在拆分数据集之前进行。\n\n\n\n\n2.8.3.7 自然语言处理\n自然语言处理（NLP）是指对文本数据进行处理，如分词、词干提取、词形还原、停用词过滤、词频统计、TF-IDF计算等。\ntextrecipes包是recipes包的扩展，提供了一系列用于文本数据处理的函数。step_tokenize()、step_stem()、step_lemma()、step_stopwords()、step_tf()、step_tfidf()等函数可以实现分词、词干提取、词形还原、停用词过滤、词频统计、TF-IDF计算等。可以在Cookbook - Using more complex recipes involving text中参考相关函数的使用方法。但是，textrecipes包目前还不支持中文文本的处理，可能需要使用jiebaR包（jiebaR 中文分词文档）等其他包来处理中文文本。\n\n\n\n2.8.4 tidy\n首先，为ames数据集创建一个recipe对象。然后，使用tidy()函数查看recipe对象的内容摘要。\nid参数可以用于指定recipe步骤函数的标识符。在多次添加相同的步骤函数时，可以使用id参数来区分这些步骤函数。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n         Latitude + Longitude, data = ames_train) |&gt;\n  step_log(Gr_Liv_Area, base = 10) |&gt;\n  step_other(Neighborhood, threshold = 0.01, id = \"my_id\") |&gt; # 指定id参数\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\")) |&gt;\n  step_ns(Latitude, Longitude, deg_free = 20) -&gt; ames_recipe\n\names_recipe |&gt;\n  tidy()\n\n\n# A tibble: 5 × 6\n  number operation type     trained skip  id            \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;         \n1      1 step      log      FALSE   FALSE log_yQoQt     \n2      2 step      other    FALSE   FALSE my_id         \n3      3 step      dummy    FALSE   FALSE dummy_EvyKp   \n4      4 step      interact FALSE   FALSE interact_VANTp\n5      5 step      ns       FALSE   FALSE ns_J20uP      \n\n\n使用ames_recipe对象建立workflow：\n\n\n代码\nworkflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(ames_recipe) -&gt; lm_workflow\n\nlm_workflow |&gt;\n  fit(data = ames_train) -&gt; lm_fit\n\n\n可以使用tidy()函数并指定id参数，查看对应id步骤的结果，也可以指定number参数，查看对应的结果：\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) |&gt;\n  tidy(id = \"my_id\")\n\n\n# A tibble: 21 × 3\n   terms        retained           id   \n   &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;\n 1 Neighborhood North_Ames         my_id\n 2 Neighborhood College_Creek      my_id\n 3 Neighborhood Old_Town           my_id\n 4 Neighborhood Edwards            my_id\n 5 Neighborhood Somerset           my_id\n 6 Neighborhood Northridge_Heights my_id\n 7 Neighborhood Gilbert            my_id\n 8 Neighborhood Sawyer             my_id\n 9 Neighborhood Northwest_Ames     my_id\n10 Neighborhood Sawyer_West        my_id\n# ℹ 11 more rows\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) |&gt;\n  tidy(number = 3)\n\n\n# A tibble: 25 × 3\n   terms        columns            id         \n   &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;      \n 1 Neighborhood College_Creek      dummy_EvyKp\n 2 Neighborhood Old_Town           dummy_EvyKp\n 3 Neighborhood Edwards            dummy_EvyKp\n 4 Neighborhood Somerset           dummy_EvyKp\n 5 Neighborhood Northridge_Heights dummy_EvyKp\n 6 Neighborhood Gilbert            dummy_EvyKp\n 7 Neighborhood Sawyer             dummy_EvyKp\n 8 Neighborhood Northwest_Ames     dummy_EvyKp\n 9 Neighborhood Sawyer_West        dummy_EvyKp\n10 Neighborhood Mitchell           dummy_EvyKp\n# ℹ 15 more rows\n\n\n\n\n2.8.5 “roles”变量\n有一部分变量，既不是预测变量，也不是因子变量，但在数据集中可能起到建模之外的作用。可以使用add_role(), remove_role()和update_role()函数来指定这些变量的角色。同时，可以为step_*()函数指定roles参数，不过大部分step_*()函数都会自动给定变量的角色。\n代码示例：\n\n\n代码\names_recipe |&gt;\n  update_role(address, new_role = \"street address\") # 对于已建好的recipe对象，使用update_role()函数来更新变量的角色，在构建recipe对象时，应使用add_role()函数。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型性能评估",
    "href": "chapters/tidymodels-基础.html#模型性能评估",
    "title": "2  tidymodels-基础",
    "section": "2.9 模型性能评估",
    "text": "2.9 模型性能评估\n\n\n\n\n\n\n重要\n\n\n\n重采样方法是最有效的验证方法。\n\n\nyardstick包是tidymodels核心包之一，可以用于模型性能评估。按结果变量的类型，即数值变量、二分类变量和多分类变量，模型性能评估的指标也有所不同。\n\n2.9.1 数值变量-回归模型\names数据集的预测模型lm_fit包含了回归模型和预测集，同时有交互作用和经纬度样条函数。首先，使用predict()函数计算预测值。\n\n\n代码\nlm_fit |&gt;\n  predict(new_data = ames_test |&gt;\n            select(-Sale_Price)) -&gt; ames_test_results\n\names_test_results |&gt;\n  head()\n\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.17\n3  5.28\n4  5.05\n5  5.51\n6  5.42\n\n\n将预测值和实际值放在一起，使用bind_cols()函数：\n\n\n代码\names_test_results |&gt;\n  bind_cols(ames_test |&gt;\n              select(Sale_Price)) -&gt; ames_test_results\n\names_test_results |&gt;\n  head()\n\n\n# A tibble: 6 × 2\n  .pred Sale_Price\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  5.07       5.02\n2  5.17       5.24\n3  5.28       5.28\n4  5.05       5.06\n5  5.51       5.60\n6  5.42       5.33\n\n\n首先，作图查看预测值和实际值的关系：\n\n\n代码\nggplot(ames_test_results, aes(x = Sale_Price, y = .pred)) + \n  geom_abline(lty = 2) + # 添加对角线\n  geom_point(alpha = 0.5) + \n  labs(y = \"Predicted Sale Price (log10)\", x = \"Sale Price (log10)\") +\n  coord_obs_pred() # 使x轴和y轴的刻度一致\n\n\n\n\n\n\n\n\n图 2.6: 预测值和实际值的关系(log10)\n\n\n\n\n\n由 图 2.6 发现，有几个预测值和实际值的偏差较大。使用rmse()函数计算均方根误差，rsq函数计算R^2，mae函数计算平均绝对误差。\n\n\n代码\names_test_results |&gt;\n  rmse(truth = Sale_Price, estimate = .pred) # 计算单一指标\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      0.0754\n\n\n代码\names_metrics &lt;- metric_set(rmse, rsq, mae) # 创建指标集\n\names_test_results |&gt;\n  ames_metrics(truth = Sale_Price, estimate = .pred) # 同时计算多个指标\n\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      0.0754\n2 rsq     standard      0.826 \n3 mae     standard      0.0546\n\n\n\n\n2.9.2 二分类变量-logistic回归模型\n使用modeldata包（tidymodels核心包之一）中的two_class_example数据集，这是一个模拟了logistic回归模型预测结果的数据集。\n\n\n代码\ndata(two_class_example, package = \"modeldata\")\ntibble(two_class_example) |&gt;\n  head()\n\n\n# A tibble: 6 × 4\n  truth   Class1   Class2 predicted\n  &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    \n1 Class2 0.00359 0.996    Class2   \n2 Class1 0.679   0.321    Class1   \n3 Class2 0.111   0.889    Class2   \n4 Class1 0.735   0.265    Class1   \n5 Class2 0.0162  0.984    Class2   \n6 Class1 0.999   0.000725 Class1   \n\n\n对于logistic回归模型，模型性能评估指标有很多，列举如下：\n\nconf_mat：混淆矩阵\n\n\n\n代码\ntwo_class_example |&gt;\n  conf_mat(truth = truth, estimate = predicted)\n\n\n          Truth\nPrediction Class1 Class2\n    Class1    227     50\n    Class2     31    192\n\n\n\naccuracy：准确率\n\n\n\n代码\ntwo_class_example |&gt;\n  accuracy(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.838\n\n\n\nmcc：Matthews相关系数\n\n\n\n代码\ntwo_class_example |&gt;\n  mcc(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mcc     binary         0.677\n\n\n\nf_meas：F1值，精确率和召回率的调和平均数\n\n\n\n代码\ntwo_class_example |&gt;\n  f_meas(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary         0.849\n\n\n\nroc_curve和roc_auc：ROC曲线和AUC\n\n\n\n代码\ntwo_class_example |&gt;\n  roc_curve(truth = truth, Class1) -&gt; two_class_curve\n\ntwo_class_curve\n\n\n# A tibble: 502 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 -Inf           0                 1\n 2    1.79e-7     0                 1\n 3    4.50e-6     0.00413           1\n 4    5.81e-6     0.00826           1\n 5    5.92e-6     0.0124            1\n 6    1.22e-5     0.0165            1\n 7    1.40e-5     0.0207            1\n 8    1.43e-5     0.0248            1\n 9    2.38e-5     0.0289            1\n10    3.30e-5     0.0331            1\n# ℹ 492 more rows\n\n\n代码\ntwo_class_example |&gt;\n  roc_auc(truth = truth, Class1)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.939\n\n\n\n\n代码\ntwo_class_curve |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n图 2.7: ROC曲线\n\n\n\n\n\n\n\n2.9.3 多分类变量-多分类模型\n\n\n代码\ndata(hpc_cv)\ntibble(hpc_cv) |&gt;\n  head()\n\n\n# A tibble: 6 × 7\n  obs   pred     VF      F       M          L Resample\n  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   \n1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01  \n2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01  \n3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01  \n4 VF    VF    0.929 0.0653 0.00579 0.0000156  Fold01  \n5 VF    VF    0.942 0.0543 0.00381 0.00000729 Fold01  \n6 VF    VF    0.951 0.0462 0.00272 0.00000384 Fold01  \n\n\n对于多分类模型，使用离散类预测的指标函数与二进制指标函数相同，如accuracy, mcc, f_meas等。\n其他指标函数包括：\n\nsensitivity：灵敏度，需要用estimator参数指定函数\n\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"macro\") # macro表示宏平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 sensitivity macro          0.560\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"micro\") # micro表示微平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 sensitivity micro          0.709\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"macro_weighted\") # macro_weighted表示加权宏平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator     .estimate\n  &lt;chr&gt;       &lt;chr&gt;              &lt;dbl&gt;\n1 sensitivity macro_weighted     0.709\n\n\n\nroc_auc：多分类模型的AUC，必须向函数提供所有的类别概率列\n\n\n\n代码\nhpc_cv |&gt;\n  roc_auc(truth = obs, VF, F, M, L) # 这里也可以指定estimator参数\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.829\n\n\nhpc_cv数据集中，有Resample列，是交叉验证的分组。可以利用group_by()函数为每个分组计算指标或作图，如 图 2.8 所示。\n\n\n代码\nhpc_cv |&gt;\n  group_by(Resample) |&gt;\n  roc_curve(obs, VF, F, M, L) |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n图 2.8: 分组ROC曲线\n\n\n\n\n\n\n\n\n\n\n图 2.1: 销售价格（美元）\n图 2.2: 对数变换后的销售价格（美元）\n图 2.3: 房屋销售价格分布(log)，虚线代表四分位数\n图 2.4: 五种不同类型建筑的总居住面积与销售价格的关系（log10变换后）\n图 2.5: 销售价格与纬度的关系\n图 2.6: 预测值和实际值的关系(log10)\n图 2.7: ROC曲线\n图 2.8: 分组ROC曲线",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html",
    "href": "chapters/tidymodels-进阶.html",
    "title": "3  tidymodels-进阶",
    "section": "",
    "text": "3.1 重采样方法\n---\ntitle: 重采样方法的数据分割\n---\nflowchart TD\nA(原始数据) --&gt; B[[训练集]]\nA --&gt; C[[测试集]]\nB --&gt; D{{重采样1}}\nB --&gt; E{{重采样2}}\nB --&gt; F{{重采样n}}\nD --&gt; G[[分析集]]\nD --&gt; H[[评估集]]\nE --&gt; I[[分析集]]\nE --&gt; J[[评估集]]\nF --&gt; K[[分析集]]\nF --&gt; L[[评估集]]\nD -.- E\nE -.- F\n\n\n\n\n图 3.1\n偏倚bias：数据中的真实模式或关系与模型所能模拟的模式类型之间的差异。运用合理的重采样方法，可以有效减小偏倚。\n重采样只在训练集上进行，测试集不参与重采样。每次重采样，训练集都会被划分为分析集和评估集。分析集用于训练模型，评估集用于评估模型的性能，如 图 3.1 所示。模型性能的最终估计值是所有评估集重复统计的平均值。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html#重采样方法",
    "href": "chapters/tidymodels-进阶.html#重采样方法",
    "title": "3  tidymodels-进阶",
    "section": "",
    "text": "3.1.1 交叉验证CV\n\nk折交叉验证k-CV\n交叉验证是一种重采样方法，最常见的是k折交叉验证。在k折交叉验证中，数据被分为k个子集，其中一个子集被保留作为评估集，其余k-1个子集被用于训练模型。这个过程重复k次，每个子集都有一次机会作为评估集。最后，模型性能的最终估计值是所有评估集重复统计的平均值。\nvfold_cv()函数可以用于创建k折交叉验证。\n\n\n\n\n\n\n重要\n\n\n\nk值越大，重取样估计值偏倚越小，但方差越大。通常k值取5或10。\n\n\n\n\n代码\nset.seed(123)\ntidymodels_prefer()\n\n# 10折交叉验证\names_train |&gt;\n  vfold_cv(v = 10) -&gt; ames_folds\names_folds\n\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   &lt;list&gt;             &lt;chr&gt; \n 1 &lt;split [2107/235]&gt; Fold01\n 2 &lt;split [2107/235]&gt; Fold02\n 3 &lt;split [2108/234]&gt; Fold03\n 4 &lt;split [2108/234]&gt; Fold04\n 5 &lt;split [2108/234]&gt; Fold05\n 6 &lt;split [2108/234]&gt; Fold06\n 7 &lt;split [2108/234]&gt; Fold07\n 8 &lt;split [2108/234]&gt; Fold08\n 9 &lt;split [2108/234]&gt; Fold09\n10 &lt;split [2108/234]&gt; Fold10\n\n\n\n\n重复k折交叉验证repeated k-CV\n重复k折交叉验证是k折交叉验证的扩展，它重复k折交叉验证多次。重复k折交叉验证的优点是它提供了更准确的模型性能估计，但是计算成本更高。\n在vfold_cv()函数中，可以使用repeats参数指定重复次数。\n\n\n代码\names_train |&gt;\n  vfold_cv(v = 10, repeats = 5)\n\n\n#  10-fold cross-validation repeated 5 times \n# A tibble: 50 × 3\n   splits             id      id2   \n   &lt;list&gt;             &lt;chr&gt;   &lt;chr&gt; \n 1 &lt;split [2107/235]&gt; Repeat1 Fold01\n 2 &lt;split [2107/235]&gt; Repeat1 Fold02\n 3 &lt;split [2108/234]&gt; Repeat1 Fold03\n 4 &lt;split [2108/234]&gt; Repeat1 Fold04\n 5 &lt;split [2108/234]&gt; Repeat1 Fold05\n 6 &lt;split [2108/234]&gt; Repeat1 Fold06\n 7 &lt;split [2108/234]&gt; Repeat1 Fold07\n 8 &lt;split [2108/234]&gt; Repeat1 Fold08\n 9 &lt;split [2108/234]&gt; Repeat1 Fold09\n10 &lt;split [2108/234]&gt; Repeat1 Fold10\n# ℹ 40 more rows\n\n\n\n\n留一法LOO\n留一法LOO是k折交叉验证的一个特例，其中k等于训练集的观测数。这时，每个评估集只包含一个观测。LOO的优点是它提供了最小的偏倚，但是计算成本很高。一般来说，LOO不适用于大型数据集。\n\n\n蒙特卡罗交叉验证MCCV\n蒙特卡罗交叉验证是一种重复随机划分数据的方法。在每次重复中，数据被随机划分为训练集和评估集，且最终产生的评估集互斥。这种方法的优点是它可以提供更准确的模型性能估计，但是计算成本更高。\nmc_cv()函数可以用于创建蒙特卡罗交叉验证。其中，prop参数指定训练集的比例，times参数指定重复次数。\n\n\n代码\names_train |&gt;\n  mc_cv(prop = 9/10, times = 20)\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 20 resamples  \n# A tibble: 20 × 2\n   splits             id        \n   &lt;list&gt;             &lt;chr&gt;     \n 1 &lt;split [2107/235]&gt; Resample01\n 2 &lt;split [2107/235]&gt; Resample02\n 3 &lt;split [2107/235]&gt; Resample03\n 4 &lt;split [2107/235]&gt; Resample04\n 5 &lt;split [2107/235]&gt; Resample05\n 6 &lt;split [2107/235]&gt; Resample06\n 7 &lt;split [2107/235]&gt; Resample07\n 8 &lt;split [2107/235]&gt; Resample08\n 9 &lt;split [2107/235]&gt; Resample09\n10 &lt;split [2107/235]&gt; Resample10\n11 &lt;split [2107/235]&gt; Resample11\n12 &lt;split [2107/235]&gt; Resample12\n13 &lt;split [2107/235]&gt; Resample13\n14 &lt;split [2107/235]&gt; Resample14\n15 &lt;split [2107/235]&gt; Resample15\n16 &lt;split [2107/235]&gt; Resample16\n17 &lt;split [2107/235]&gt; Resample17\n18 &lt;split [2107/235]&gt; Resample18\n19 &lt;split [2107/235]&gt; Resample19\n20 &lt;split [2107/235]&gt; Resample20\n\n\n\n\n\n3.1.2 验证集\n验证集方法其实是只进行一次重采样，将数据分为训练集和验证集。验证集方法的优点是计算成本低，但是它提供的模型性能估计可能不准确。\n\n\n代码\names |&gt;\n  initial_validation_split(prop = c(0.6, 0.2)) |&gt; # 训练集60%，验证集20%，测试集20%\n  validation_set() # 验证集\n\n\n# A tibble: 1 × 2\n  splits             id        \n  &lt;list&gt;             &lt;chr&gt;     \n1 &lt;split [1758/586]&gt; validation\n\n\n\n\n3.1.3 Bootstrap\nBootstrap是一种重采样方法，它通过有放回地抽样来创建新的数据集。在每次重采样中，数据集的大小保持不变，但是每个观测可以被多次抽样。Bootstrap的优点是产生的性能估计方差较小，但是它可能产生较大的偏倚，尤其会低估准确率。\nbootstraps()函数可以用于创建Bootstrap。\n\n\n代码\names_train |&gt;\n  bootstraps(times = 10)\n\n\n# Bootstrap sampling \n# A tibble: 10 × 2\n   splits             id         \n   &lt;list&gt;             &lt;chr&gt;      \n 1 &lt;split [2342/881]&gt; Bootstrap01\n 2 &lt;split [2342/868]&gt; Bootstrap02\n 3 &lt;split [2342/896]&gt; Bootstrap03\n 4 &lt;split [2342/852]&gt; Bootstrap04\n 5 &lt;split [2342/861]&gt; Bootstrap05\n 6 &lt;split [2342/871]&gt; Bootstrap06\n 7 &lt;split [2342/852]&gt; Bootstrap07\n 8 &lt;split [2342/857]&gt; Bootstrap08\n 9 &lt;split [2342/857]&gt; Bootstrap09\n10 &lt;split [2342/880]&gt; Bootstrap10\n\n\n\n\n3.1.4 滚动抽样-时间序列\n滚动预测原点重采样方法是一种时间序列数据的重采样方法。初始训练集和评估集的大小是指定的。重采样的第一次迭代从序列的起点开始。第二次迭代向后移位一定数量的样本。流程如 图 3.2 所示。\n\n\n\n\n\n\n图 3.2: 滚动预测原点重采样\n\n\n\n假设有一个时间序列数据集，由6组30天的数据块组成。可以设置初始训练集和评估集的大小为30天。第一次迭代，训练集包含第1-30天的数据，评估集包含第31-60天的数据。第二次迭代，训练集包含第31-60天的数据，评估集包含第61-90天的数据。以此类推。\nrolling_origin()函数可以用于创建滚动预测原点重采样。\n\n\n代码\ntibble(x = 1:365) |&gt;\n  rolling_origin(initial = 6 * 30, # 初始训练集大小\n                 assess = 30, # 评估集大小\n                 skip = 29, # 每次迭代的跳跃步长\n                 cumulative = FALSE) -&gt; time_slices # 是否累积\n\ndata_range &lt;- function(x) {\n  summarise(x, first = min(x), last = max(x))\n}\n\ntime_slices$splits |&gt;\n  map_dfr(~ analysis(.x) |&gt;\n            data_range())\n\n\n# A tibble: 6 × 2\n  first  last\n  &lt;int&gt; &lt;int&gt;\n1     1   180\n2    31   210\n3    61   240\n4    91   270\n5   121   300\n6   151   330\n\n\n代码\ntime_slices$splits |&gt;\n  map_dfr(~ assessment(.x) |&gt;\n            data_range())\n\n\n# A tibble: 6 × 2\n  first  last\n  &lt;int&gt; &lt;int&gt;\n1   181   210\n2   211   240\n3   241   270\n4   271   300\n5   301   330\n6   331   360",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html#评估重采样性能",
    "href": "chapters/tidymodels-进阶.html#评估重采样性能",
    "title": "3  tidymodels-进阶",
    "section": "3.2 评估重采样性能",
    "text": "3.2 评估重采样性能\n首先建立一个随机森林模型。\n\n\n代码\nrf_model &lt;- \n  rand_forest(trees = 1000) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"regression\")\n\nrf_workflow &lt;- \n  workflow() |&gt;\n  add_formula(\n    Sale_Price ~ Neighborhood + Gr_Liv_Area +\n      Year_Built + Bldg_Type + Latitude + Longitude\n  ) |&gt;\n  add_model(rf_model)\n\nrf_fit &lt;- \n  rf_workflow |&gt;\n  fit(data = ames_train)\n\n\n\n3.2.1 十折交叉验证\n使用control_resamples()函数设置模型重采样控制参数；使用fit_resamples()函数对模型进行重采样训练和评估。\n\n\n代码\nkeep_pred &lt;-\n  control_resamples(save_pred = TRUE, save_workflow = TRUE)\n\names_train |&gt;\n  vfold_cv(v = 10) -&gt; ames_folds\n\nset.seed(123)\nrf_workflow |&gt;\n  fit_resamples(\n    resamples = ames_folds,\n    control = keep_pred\n  ) -&gt; rf_res\n\nrf_res\n\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits             id     .metrics         .notes           .predictions\n   &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [2107/235]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [2107/235]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [2108/234]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [2108/234]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [2108/234]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [2108/234]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [2108/234]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [2108/234]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [2108/234]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [2108/234]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n在rf_res中，包含了每次重采样的模型性能评估结果。可以使用collect_metrics()函数提取模型性能指标。\n\n\n代码\nrf_res |&gt;\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0728    10 0.00261 Preprocessor1_Model1\n2 rsq     standard   0.830     10 0.0111  Preprocessor1_Model1\n\n\n方法的模型性能评估结果可以使用collect_predictions()函数提取。\n\n\n代码\nrf_res |&gt;\n  collect_predictions() -&gt; assess_res\n\nassess_res\n\n\n# A tibble: 2,342 × 5\n   id     .pred  .row Sale_Price .config             \n   &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;               \n 1 Fold01  5.07     1       5.10 Preprocessor1_Model1\n 2 Fold01  5.17    16       5.04 Preprocessor1_Model1\n 3 Fold01  4.91    27       4.90 Preprocessor1_Model1\n 4 Fold01  5.04    37       5.09 Preprocessor1_Model1\n 5 Fold01  5.02    40       5.04 Preprocessor1_Model1\n 6 Fold01  5.15    44       4.97 Preprocessor1_Model1\n 7 Fold01  5.12    57       5.10 Preprocessor1_Model1\n 8 Fold01  4.98    60       4.90 Preprocessor1_Model1\n 9 Fold01  4.92    69       5.01 Preprocessor1_Model1\n10 Fold01  5.08    78       4.88 Preprocessor1_Model1\n# ℹ 2,332 more rows\n\n\n对性能评估结果assess_res进行可视化，如 图 3.3 所示。\n\n\n代码\nassess_res |&gt;\n  ggplot(aes(x = Sale_Price, y = .pred)) +\n  geom_point(alpha = 0.15) +\n  # 把x&lt;4.5的点标记成红色\n  geom_point(data = filter(assess_res, Sale_Price &lt; 4.5), color = \"red\", alpha = 0.25) +\n  geom_abline(color = \"red\") + \n  coord_obs_pred() +\n  theme_bw() +\n  ylab(\"Predicted\")\n\n\n\n\n\n\n\n\n图 3.3: 重采样性能评估结果(log10)\n\n\n\n\n\n图 3.3 中，标红的两个点表示销售价格较低的这两个房屋预测值大大偏高。可以在assess_res中定位到这两个数据，进而分析特定预测性能较差的可能原因。\n\n\n代码\nover_predicted &lt;-\n  assess_res |&gt;\n  mutate(residual = Sale_Price - .pred) |&gt; # 计算残差\n  arrange(desc(abs(residual))) |&gt; # 按残差绝对值降序排列\n  slice(1:2) # 取前两个数据\n\nover_predicted\n\n\n# A tibble: 2 × 6\n  id     .pred  .row Sale_Price .config              residual\n  &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;\n1 Fold03  4.90   319       4.12 Preprocessor1_Model1   -0.783\n2 Fold06  4.87    32       4.11 Preprocessor1_Model1   -0.767\n\n\n代码\names_train |&gt;\n  slice(over_predicted$.row) |&gt; # 取出这两个数据\n  select(Gr_Liv_Area, Neighborhood, Year_Built, Bedroom_AbvGr, Full_Bath) # 选择感兴趣的变量\n\n\n# A tibble: 2 × 5\n  Gr_Liv_Area Neighborhood           Year_Built Bedroom_AbvGr Full_Bath\n        &lt;int&gt; &lt;fct&gt;                       &lt;int&gt;         &lt;int&gt;     &lt;int&gt;\n1         733 Iowa_DOT_and_Rail_Road       1952             2         1\n2         832 Old_Town                     1923             2         1\n\n\n\n\n3.2.2 验证集\n使用fit_resamples()函数对模型进行重采样训练和评估。\n\n\n代码\names |&gt;\n  initial_validation_split(prop = c(0.6, 0.2)) |&gt;\n  validation_set() -&gt; val_set # 划分验证集\n\nrf_workflow |&gt;\n  fit_resamples(resamples = val_set) -&gt; val_res # 对验证集进行重采样训练和评估\n\nval_res\n\n\n# Resampling results\n#  \n# A tibble: 1 × 4\n  splits             id         .metrics         .notes          \n  &lt;list&gt;             &lt;chr&gt;      &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [1758/586]&gt; validation &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\n代码\ncollect_metrics(val_res) # 提取模型性能指标\n\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.0657     1      NA Preprocessor1_Model1\n2 rsq     standard   0.845      1      NA Preprocessor1_Model1",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html#并行计算",
    "href": "chapters/tidymodels-进阶.html#并行计算",
    "title": "3  tidymodels-进阶",
    "section": "3.3 并行计算",
    "text": "3.3 并行计算\ntune包使用foreach包来进行并行计算。\nparallel包可以计算本机的并行计算能力。\n\n\n代码\nparallel::detectCores(logical = FALSE) # 物理核心数\n\n\n[1] 12\n\n\n代码\nparallel::detectCores(logical = TRUE) # 逻辑核心数，包括超线程\n\n\n[1] 16\n\n\ndoParallel包可以使用registerDoParallel()函数注册并行计算。\n\n\n代码\nlibrary(doParallel)\n\ncl &lt;- makePSOCKcluster(4) # 创建4个核心的并行计算集群\nregisterDoParallel(cl) # 注册并行计算\n\n## 运行fit_resamples()函数----------------\n\nstopCluster(cl) # 关闭并行计算集群",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html#利用重采样方法比较模型",
    "href": "chapters/tidymodels-进阶.html#利用重采样方法比较模型",
    "title": "3  tidymodels-进阶",
    "section": "3.4 利用重采样方法比较模型",
    "text": "3.4 利用重采样方法比较模型\n\n\n代码\nrm(list = ls())\nload(\"../data/tidymodels_2_1.rda\")\n\n\n\n3.4.1 建立多个模型\n建立三个不同的线性回归模型。\n\n\n代码\n## 基本模型----------------\nbasic_rec &lt;-\n  ames_train |&gt;\n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n           Latitude + Longitude) |&gt;\n  step_log(Gr_Liv_Area, base = 10) |&gt;\n  step_other(Neighborhood, threshold = 0.01) |&gt;\n  step_dummy(all_nominal_predictors())\n\n## 基本模型 + 交互项----------------\ninteraction_rec &lt;-\n  basic_rec |&gt;\n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\"))\n\n## 基本模型 + 交互项 + 自然样条----------------\nspline_rec &lt;- \n  interaction_rec |&gt; \n  step_ns(Latitude, Longitude, deg_free = 50)\n\n## 建立模型----------------\npreproc &lt;- \n  list(basic = basic_rec, \n       interact = interaction_rec, \n       splines = spline_rec\n  )\n\nlm_models &lt;-\n  preproc |&gt;\n  workflow_set(list(lm = linear_reg()), cross = FALSE) # 建立线性回归模型，不进行重采样\n\nlm_models\n\n\n# A workflow set/tibble: 3 × 4\n  wflow_id    info             option    result    \n  &lt;chr&gt;       &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 basic_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 interact_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 splines_lm  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n使用workflow_map()函数对三个模型进行重采样。verbose = TRUE参数可以显示进度条，seed = 123参数可以设置随机种子。\n\n\n代码\nlm_models &lt;-\n  lm_models |&gt;\n  workflow_map(\n    \"fit_resamples\",\n    seed = 123,\n    verbose = TRUE,\n    resamples = ames_folds,\n    control = keep_pred\n  )\n\nlm_models\n\n\n# A workflow set/tibble: 3 × 4\n  wflow_id    info             option    result   \n  &lt;chr&gt;       &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 basic_lm    &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n2 interact_lm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n3 splines_lm  &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n\n\n使用collect_metrics()函数提取模型性能指标。\n\n\n代码\nlm_models |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\")\n\n\n# A tibble: 3 × 9\n  wflow_id    .config      preproc model .metric .estimator   mean     n std_err\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 basic_lm    Preprocesso… recipe  line… rmse    standard   0.0794    10 0.00318\n2 interact_lm Preprocesso… recipe  line… rmse    standard   0.0789    10 0.00320\n3 splines_lm  Preprocesso… recipe  line… rmse    standard   0.0777    10 0.00308\n\n\n添加其他模型时，需要提前在其他模型重采样流程中设置save_workflow = TRUE。使用as_workflow_set()函数将保存的工作流转换为workflow_set对象。\n\n\n代码\nfour_models &lt;-\n  as_workflow_set(random_forest = rf_res) |&gt;\n  bind_rows(lm_models)\n\nfour_models\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id      info             option    result   \n  &lt;chr&gt;         &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 random_forest &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;rsmp[+]&gt;\n2 basic_lm      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n3 interact_lm   &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n4 splines_lm    &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n\n\n使用autoplot()函数对模型进行可视化。\n\n\n代码\nlibrary(ggrepel)\nfour_models |&gt;\n  autoplot(metric = \"rsq\") + # 可视化R^2\n  geom_text_repel(aes(label = wflow_id), nudge_x = 1/8, nudge_y = 1/100) + # 添加模型名称\n  theme(legend.position = \"none\") # 隐藏图例\n\n\n\n\n\n\n\n\n图 3.4\n\n\n\n\n\n由 图 3.4 可以看出，随机森林模型的R2值最高，且随着模型复杂度的增加，R2值也在增加，说明线性模型有细微的改进。\n\n\n3.4.2 比较重采样的性能统计\n在不同的线性模型之间，R2值的差异并不大。但是，这种差异是否具有统计学意义仍需进一步检验。\n\n3.4.2.1 假设检验\n可以用配对t检验方法检验不同模型之间的R2值差异是否具有统计学意义。\n\n\n代码\nrsq_indiv_estimates &lt;-\n  four_models |&gt;\n  collect_metrics(summarize = FALSE) |&gt; # 提取模型性能指标\n  filter(.metric == \"rsq\") # 提取R^2^值\n\nrsq_wider &lt;-\n  rsq_indiv_estimates |&gt;\n  select(wflow_id, .estimate, id) |&gt;\n  pivot_wider(id_cols = \"id\", names_from = \"wflow_id\", values_from = \".estimate\")\n\ncorrr::correlate(rsq_wider %&gt;% select(-id), quiet = TRUE) # 计算R^2^值的相关系数\n\n\n# A tibble: 4 × 5\n  term          random_forest basic_lm interact_lm splines_lm\n  &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 random_forest        NA        0.925       0.933      0.915\n2 basic_lm              0.925   NA           0.996      0.977\n3 interact_lm           0.933    0.996      NA          0.977\n4 splines_lm            0.915    0.977       0.977     NA    \n\n\n\n\n代码\n# 基本模型和交互模型-------------------------------------------------------\nrsq_wider |&gt;\n  with(t.test(splines_lm, basic_lm, paired = TRUE)) |&gt;\n  tidy() |&gt;\n  select(estimate, p.value, starts_with(\"conf\")) # 提取估计值、p值和置信区间\n\n\n# A tibble: 1 × 4\n  estimate p.value conf.low conf.high\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  0.00770  0.0391 0.000480    0.0149\n\n\n根据假设检验结果，p值不显著，且R2值差异仅为0.77%。因此，不同模型之间的R2值差异不具有统计学意义。\n\n\n3.4.2.2 贝叶斯\n\n3.4.2.2.1 随机截距模型\n使用tidyposterior包中的perf_mod()函数可以建立贝叶斯模型，并将其与重采样统计量拟合。\n\n\n代码\npackages &lt;- c(\"tidyposterior\", \"rstanarm\")\nfor (pkg in packages) {\n  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {\n    install.packages(pkg, dependencies = TRUE)\n    require(pkg, character.only = TRUE, quietly = TRUE)\n  }\n}\n\n# 建立贝叶斯先验模型--------------------------------------------------------\nrsq_anova &lt;-\n  four_models |&gt;\n  perf_mod(\n    metric = \"rsq\",\n    prior_intercept = rstanarm::student_t(df = 1), # 指定拟合模型时用于截距项的先验分布\n    chains = 4,\n    iter = 5000,\n    seed = 123,\n    refresh = 0 # 不显示进度条\n  )\n\n# 提取模型后验信息-----------------------------------------------------------\nmodel_post &lt;-\n  rsq_anova |&gt;\n  tidy(seed = 1103)\n\n\n\n\n代码\nmodel_post |&gt;\n  mutate(model = forcats::fct_inorder(model)) |&gt; # 对模型名称进行排序\n  ggplot(aes(x = posterior)) +\n  geom_histogram(bins = 50, color = \"white\", fill = \"blue\", alpha = 0.4) +\n  facet_wrap(~ model, ncol = 1) +\n  theme_bw()\n\n\n\n\n\n\n\n\n图 3.5: 后验分布\n\n\n\n\n\n图 3.5 和 图 3.6 分别展示了不同模型的平均R2值的估计概率分布和置信区间。可以看出，各个模型的后验分布有所重叠，尤其是三个线性模型之间，说明不同模型之间的R2值差异不具有统计学意义。\n\n\n代码\nrsq_anova |&gt;\n  autoplot() +\n  geom_text_repel(aes(label = workflow), nudge_x = 1/8, nudge_y = 1/100) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n图 3.6: 后验分布的置信区间\n\n\n\n\n\n使用contrast_models()函数对不同模型的R2差异的后验分布进行比较。\n\n\n代码\nrsq_diff &lt;-\n  rsq_anova |&gt;\n  contrast_models(\n    list_1 = \"splines_lm\",\n    list_2 = \"basic_lm\",\n    seed = 123\n  )\n\nrsq_diff |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(x = difference)) +\n  geom_vline(xintercept = 0, lty = 2) + \n  geom_histogram(bins = 50, color = \"white\", fill = \"red\", alpha = 0.4)\n\n\n\n\n\n\n\n\n图 3.7: 决定系数差异的后验分布\n\n\n\n\n\n如 图 3.7 所示，不同模型之间的R2值差异的后验分布均值接近于0，且置信区间包含0，说明不同模型之间的R2值差异不具有统计学意义。可以进一步使用summary函数计算分布的平均值以及可信区间。其中，probability表示差异大于0的概率，mean表示差异的平均值。\n\n\n代码\nrsq_diff |&gt;\n  summary()\n\n\n# A tibble: 1 × 9\n  contrast        probability    mean   lower  upper  size pract_neg pract_equiv\n  &lt;chr&gt;                 &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 splines_lm vs …       0.990 0.00768 0.00232 0.0130     0        NA          NA\n# ℹ 1 more variable: pract_pos &lt;dbl&gt;\n\n\n\n\n代码\nrsq_anova |&gt;\n  autoplot(type = \"ROPE\", size = 0.02) +\n  geom_text_repel(aes(label = workflow)) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n图 3.8: 效应大小为 2% 的实际等效概率\n\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n重采样的次数越多，后验分布的形状越接近于正态分布。因此，可以通过增加重采样次数来提高模型的稳定性。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-进阶.html#模型参数调优",
    "href": "chapters/tidymodels-进阶.html#模型参数调优",
    "title": "3  tidymodels-进阶",
    "section": "3.5 模型参数调优",
    "text": "3.5 模型参数调优\n\n\n\n\n\n图 3.2: 滚动预测原点重采样\n图 3.3: 重采样性能评估结果(log10)\n图 3.4: \n图 3.5: 后验分布\n图 3.6: 后验分布的置信区间\n图 3.7: 决定系数差异的后验分布\n图 3.8: 效应大小为 2% 的实际等效概率",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>tidymodels-进阶</span>"
    ]
  }
]