[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言学习笔记",
    "section": "",
    "text": "笔记集\n本笔记集整理了R语言在数据分析和可视化、统计建模、机器学习等方面的学习笔记，准备记录tidyverse、tidymodels、mlr3、R6、gt等R包的使用方法和实例。\n笔记集使用Quarto编写，并使用GitHub Pages托管，可以通过https://caowz254.github.io/ln-r/在线阅读和标注。代码部分除了参考书籍和官方文档，也使用了GitHub Copilot的AI自动补全功能，以提高编写效率。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "R语言学习笔记",
    "section": "Quarto",
    "text": "Quarto\nQuarto是R Markdown的扩展，支持多种输出格式，包括HTML、PDF、Word等。Render的核心是一个R包，它提供了一些新的语法和功能，以便更好地支持多种输出格式。Quarto的官方文档是https://quarto.org/docs/guide/。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "index.html#github-pages",
    "href": "index.html#github-pages",
    "title": "R语言学习笔记",
    "section": "GitHub Pages",
    "text": "GitHub Pages\nGitHub Pages是GitHub提供的静态网页托管服务，笔记集在本地撰写和修改，提交到GitHub后，自动构建和发布网页。Quarto有一套完整的功能，可以基本实现网页自动化部署。\n\n\n\n\n\n\n重要\n\n\n\n部署网页流程，可在RStudio terminal操作：\nquarto render # 本地完整渲染\ngit status # 检查修改情况，每次git后都要检查一下\ngit add . # 添加全部文件到暂存区，可跳过\ngit commit -a # 将暂存区文件提交到本地仓库\ngit push --all # 将本地仓库文件推送到远程仓库",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html",
    "href": "chapters/tidymodels-基础.html",
    "title": "2  tidymodels-基础",
    "section": "",
    "text": "2.1 建模基础\n---\ntitle: 建模的分类\n---\nflowchart LR\nA[模型] --- B[描述性模型]\nA --- C[推理模型]\nA --- D[预测模型]\nD --- E[无监督模型]\nD --- F[监督模型]\nE --- G[\"主成分分析(PCA)\"]\nE --- H[聚类]\nE --- I[自动编码器]\nF --- J[回归]\nF --- K[神经网络]\n---\ntitle: 模型建模的一般步骤\n---\nflowchart LR\nA[导入数据] --&gt; B[\"清洗数据(tidy)\"] ---&gt; C[\"探索性数据分析(EDA)\"] --&gt; D[特征工程] --&gt; E[建模与优化] --&gt; F[评估] --&gt; G[部署]\nF -.-&gt; C",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#练习数据和探索性数据分析",
    "href": "chapters/tidymodels-基础.html#练习数据和探索性数据分析",
    "title": "2  tidymodels-基础",
    "section": "2.2 练习数据和探索性数据分析",
    "text": "2.2 练习数据和探索性数据分析\n练习数据使用的是modeldata包中的ames数据集。数据集包括：\n\n房屋特征house characteristics，如bedrooms, garage, fireplace, pool, porch等；\n区位location；\n地块信息lot information，如zoning, shape, size等；\n条件和质量评级ratings of condition and quality；\n成交价格sale price。\n\n\n\n代码\ndata(ames)\ndim(ames)\n\n\n[1] 2930   74\n\n\n\n2.2.1 探索性数据分析-探索住宅特点\n首先关注房屋的最终销售价格（美元）。使用直方图来查看销售价格的分布情况，如 图 2.1 所示。\n\n\n代码\ntidymodels_prefer() # 用于处理包之间的函数冲突，不会输出结果\n\names |&gt;\n  ggplot(aes(x = Sale_Price)) +\n  geom_histogram(bins = 50, col = \"white\") +\n  theme_bw() -&gt; fig_0201\n\n\n\n\n代码\nfig_0201\n\n\n\n\n\n\n\n\n图 2.1: 销售价格（美元）\n\n\n\n\n\n作图发现数据是偏态的，可以使用对数变换来处理。这种转换的优点是，不会预测出负销售价格的房屋，而且预测昂贵房屋的误差也不会对模型产生过大的影响。另外，对数变换还可以稳定方差，使得模型更容易拟合。结果如 图 2.2 所示。\n\n\n代码\nfig_0201 +\n  scale_x_log10() -&gt; fig_0202\n\n\n\n\n代码\nfig_0202\n\n\n\n\n\n\n\n\n图 2.2: 对数变换后的销售价格（美元）\n\n\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n对数转换结果的主要缺点涉及到对模型结果的解释。在对数变换后，模型的系数不再是直接解释的，而是对数解释。这意味着，模型的系数是对数销售价格的变化，而不是销售价格的变化。这种情况下，需要小心解释模型的结果。\n\n\n对数转换的结果相对较好，因此可以使用对数转换后的销售价格作为目标变量。\n\n\n代码\names |&gt;\n  mutate(Sale_Price = log10(Sale_Price)) -&gt; ames",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#数据分割",
    "href": "chapters/tidymodels-基础.html#数据分割",
    "title": "2  tidymodels-基础",
    "section": "2.3 数据分割",
    "text": "2.3 数据分割\n一般会将数据集分为训练集和测试集。训练集用于拟合模型，测试集用于评估模型的性能。\n测试集只能使用一次，否则就会成为建模过程的一部分。这样会导致模型在测试集上的性能过于乐观，无法真实地评估模型的性能。\n\n2.3.1 简单随机抽样\n在tidymodels中，可以使用initial_split()函数来分割数据集。默认情况下，initial_split()函数会将数据集分为80%的训练集和20%的测试集。\n\n\n代码\nset.seed(123)\n\names_split &lt;- initial_split(ames, prop = 0.8)\n\names_split\n\n\n&lt;Training/Testing/Total&gt;\n&lt;2344/586/2930&gt;\n\n\names_split是一个rsplit对象，仅包含分区信息，可以使用training()和testing()函数来提取训练集和测试集。\n\n\n代码\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\ndim(ames_train)\n\n\n[1] 2344   74\n\n\n\n\n2.3.2 分层抽样\n在某些情况下，需要使用分层抽样。例如，如果数据集中有一个重要的类别变量，那么就需要使用分层抽样来确保训练集和测试集中都包含这个类别变量的各个水平。\n可以人为地将结果数据四等分，然后分别进行四次分层抽样，这样可以保持训练集和测试集的分布一致。\n\n\n代码\names |&gt;\n  pull(Sale_Price) |&gt; # 提取销售价格\n  density(n = 2^10) |&gt; # 生成密度估计\n  tidy() -&gt; sale_dens # 将结果转换为数据框\n\ntibble(prob = (1:3)/4, value = quantile(ames$Sale_Price, probs = prob)) |&gt; # 计算四分位数\n  mutate(y = approx(sale_dens$x, sale_dens$y, xout = value)$y) -&gt; quartiles # 计算四分位数的密度值\n\names |&gt;\n  ggplot(aes(x = Sale_Price)) +\n  geom_line(stat = \"density\") +\n  geom_segment(data = quartiles,\n               aes(x = value, xend = value, y = 0, yend = y),\n               lty = 2) +\n  labs(x = \"Sale Price (log-10 USD)\", y = NULL) +\n  theme_bw() -&gt; fig_0203\nfig_0203\n\n\n\n\n\n\n\n\n图 2.3: 房屋销售价格分布(log)，虚线代表四分位数\n\n\n\n\n\n销售价格的分布呈右偏态，廉价房屋的比例更大。因此，可以使用分层抽样来确保训练集和测试集中都包含廉价房屋。可以使用strata参数来指定分层变量。\n\n\n代码\nset.seed(123)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\ndim(ames_train)\n\n\n[1] 2342   74\n\n\n\n\n\n\n\n\n注意\n\n\n\n只能使用单列作为分层变量，不能使用多列。\n\n\n\n\n2.3.3 交叉验证-验证集的分割\n交叉验证通常用于解决模型过拟合的问题。为此，可以把数据集分为训练集、测试集和验证集，其中验证集用于调整模型的超参数。可以用initial_vadilation_split()函数来实现。\n\n\n代码\nset.seed(123)\names_val_split &lt;- initial_validation_split(ames, prop = c(0.6, 0.2))\n\names_val_split\n\n\n&lt;Training/Validation/Testing/Total&gt;\n&lt;1758/586/586/2930&gt;\n\n\n代码\names_val_train &lt;- training(ames_val_split)\names_val_test  &lt;- testing(ames_val_split)\names_val_val   &lt;- validation(ames_val_split)",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型拟合-以线性回归为例",
    "href": "chapters/tidymodels-基础.html#模型拟合-以线性回归为例",
    "title": "2  tidymodels-基础",
    "section": "2.4 模型拟合-以线性回归为例",
    "text": "2.4 模型拟合-以线性回归为例\n对于一些相对简单的模型，可以使用parsnip包中的fit和predict函数来拟合和预测。parsnip包提供了统一的接口，可以使用相同的函数来拟合不同的模型。\n使用parsnip中的linear_reg()函数指定模型类型，set_engine()函数指定模型引擎，这里的引擎一般指的是具体建模使用的软件包名称。确定模型后，可以使用fit()函数或fit_xy()函数来拟合模型。以三种常用的线性回归模型为例。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nModel fit template:\nstats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())\n\n\n代码\nlinear_reg(penalty = 1) |&gt; # panalty是glmnet的特有参数\n  set_engine(\"glmnet\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    family = \"gaussian\")\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"stan\") |&gt;\n  translate()\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\nModel fit template:\nrstanarm::stan_glm(formula = missing_arg(), data = missing_arg(), \n    weights = missing_arg(), family = stats::gaussian, refresh = 0)\n\n\n\ntranslate()函数可以提供模型转换的详细参数信息。\nmissing_arg()是占位符，表示数据未提供。\n\n以经度和纬度为自变量，销售价格为因变量，拟合线性回归模型。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") -&gt; lm_model\n\nlm_model |&gt;\n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train) -&gt; lm_form_fit\n\nlm_model |&gt;\n  fit_xy(x = ames_train |&gt;\n           select(Longitude, Latitude),\n         y = ames_train |&gt;\n           pull(Sale_Price)\n  ) -&gt; lm_xy_fit\n\nlm_form_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nlm_xy_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#提取模型结果",
    "href": "chapters/tidymodels-基础.html#提取模型结果",
    "title": "2  tidymodels-基础",
    "section": "2.5 提取模型结果",
    "text": "2.5 提取模型结果\nlm_form_fit和lm_xy_fit是parsnip模型对象，拟合模型储存在fit属性中。可以使用extract_fit_engine()函数提取拟合模型。\n\n\n代码\nlm_form_fit |&gt;\n  tidy() # 最简单的提取模型系数的方法（提取为tibble）\n\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  -300.      14.6       -20.6 1.02e-86\n2 Longitude      -2.01     0.130     -15.5 8.13e-52\n3 Latitude        2.78     0.182      15.3 1.64e-50\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt; # 提取模型\n  vcov() # 提取模型的协方差矩阵\n\n\n            (Intercept)     Longitude      Latitude\n(Intercept)  212.620590  1.6113032179 -1.4686377363\nLongitude      1.611303  0.0168165968 -0.0008694728\nLatitude      -1.468638 -0.0008694728  0.0330018995\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt;\n  summary() |&gt; # 提取模型的摘要信息\n  coef() # 提取模型的系数\n\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -300.250929 14.5815154 -20.59120 1.022609e-86\nLongitude     -2.013413  0.1296788 -15.52615 8.126177e-52\nLatitude       2.781713  0.1816642  15.31239 1.639312e-50\n\n\n代码\nlm_form_fit |&gt;\n  extract_fit_engine() |&gt;\n  gtsummary::tbl_regression() # 生成模型摘要信息\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nLongitude\n-2.0\n-2.3, -1.8\n&lt;0.001\n\n\nLatitude\n2.8\n2.4, 3.1\n&lt;0.001\n\n\n\n1 CI = Confidence Interval",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型预测",
    "href": "chapters/tidymodels-基础.html#模型预测",
    "title": "2  tidymodels-基础",
    "section": "2.6 模型预测",
    "text": "2.6 模型预测\n使用predict()函数进行预测。\n\n\n代码\names_test |&gt;\n  slice(1:5) -&gt; ames_test_small # 选择前五行数据\n\npredict(lm_form_fit, new_data = ames_test_small) # 预测结果\n\n\n# A tibble: 5 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.22\n2  5.22\n3  5.28\n4  5.24\n5  5.31\n\n\n代码\names_test_small |&gt;\n  select(Sale_Price) |&gt; # 真实值\n  bind_cols(predict(lm_form_fit, ames_test_small)) |&gt; # 预测值\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) # 预测区间\n\n\n# A tibble: 5 × 4\n  Sale_Price .pred .pred_lower .pred_upper\n       &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1       5.02  5.22        4.91        5.54\n2       5.24  5.22        4.91        5.54\n3       5.28  5.28        4.97        5.60\n4       5.06  5.24        4.92        5.56\n5       5.60  5.31        5.00        5.63\n\n\n以决策树为例，对数据进行建模\n\n\n代码\ndecision_tree(min_n = 2) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\") -&gt; tree_model\n\ntree_model |&gt;\n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train) -&gt; tree_fit\n\names_test_small |&gt;\n  select(Sale_Price) |&gt; # 真实值\n  bind_cols(predict(tree_fit, ames_test_small)) # 预测值\n\n\n# A tibble: 5 × 2\n  Sale_Price .pred\n       &lt;dbl&gt; &lt;dbl&gt;\n1       5.02  5.15\n2       5.24  5.15\n3       5.28  5.31\n4       5.06  5.15\n5       5.60  5.52\n\n\n\n\n\n\n\n\n重要\n\n\n\n可以在https://www.tidymodels.org/find/找所有可用的模型。\nparsnip_addin()函数可以在RStudio中搜索模型。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#workflow",
    "href": "chapters/tidymodels-基础.html#workflow",
    "title": "2  tidymodels-基础",
    "section": "2.7 workflow",
    "text": "2.7 workflow\n\n2.7.1 创建workflow对象\n使用lm_model来创建workflow对象，workflow对象可以将数据预处理和模型拟合整合在一起。\n\n\n代码\nlinear_reg() |&gt;\n  set_engine(\"lm\") -&gt; lm_workflow\n\n\n\n\n代码\nworkflow() |&gt;\n  add_model(lm_model) -&gt; lm_workflow\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: None\nModel: linear_reg()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\n\n\n\n注释\n\n\n\nlm_workflow中，Preprocessor为空，代表没有数据预处理。\n\n\n\n\n2.7.2 添加预处理器\n使用add_formula函数输入标准公式作为预处理器：\n\n\n代码\nlm_workflow |&gt;\n  add_formula(Sale_Price ~ Longitude + Latitude) -&gt; lm_workflow\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nworkflow对象可以使用fit()函数拟合模型，使用predict()函数进行预测。\n\n\n代码\nlm_workflow |&gt;\n  fit(data = ames_train) -&gt; lm_fit\n\nlm_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nlm_fit |&gt;\n  predict(new_data = ames_test |&gt;\n            slice(1:3)) # 预测\n\n\n# A tibble: 3 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.22\n2  5.22\n3  5.28\n\n\n可以使用update_formula函数更新预处理器：\n\n\n代码\nlm_fit |&gt;\n  update_formula(Sale_Price ~ Longitude)\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n2.7.3 添加变量\n使用add_variables函数添加变量。函数有两个参数：outcomes和predictors。支持使用c()函数添加多个变量。\n\n\n代码\nlm_workflow |&gt;\n  remove_formula() |&gt;\n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude)) -&gt; lm_workflow # 和上面的add_formula等价\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n拟合模型：\n\n\n代码\nfit(lm_workflow, data = ames_train) # 拟合模型\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n\n\n2.7.4 为workflow使用公式\n\n2.7.4.1 基于树的模型\n使用Orthodont数据集，拟合一个受试者具有随机效应的回归模型。\n在workflow中，使用add_variables()函数添加变量，使用add_model()函数添加模型。\n\n\n代码\nlibrary(multilevelmod) # parsnip扩展包，主要用于多层次模型（混合效应模型、贝叶斯层次模型等）\n\ndata(Orthodont, package = \"nlme\")\n\nlinear_reg() |&gt;\n  set_engine(\"lmer\") -&gt; multilevel_spec # lmer是lme4包中的函数，用于拟合线性混合效应模型\n  \nworkflow() |&gt;\n  add_variables(outcome = distance, predictors = c(Sex, age, Subject)) |&gt; \n  add_model(multilevel_spec, \n            formula = distance ~ Sex + (age | Subject)) -&gt; multilevel_workflow # age | Subject表示age是Subject的随机效应\n\nmultilevel_workflow |&gt;\n  fit(data = Orthodont) -&gt; multilevel_fit\n\nmultilevel_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: distance\nPredictors: c(Sex, age, Subject)\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear mixed model fit by REML ['lmerMod']\nFormula: distance ~ Sex + (age | Subject)\n   Data: data\nREML criterion at convergence: 471.1635\nRandom effects:\n Groups   Name        Std.Dev. Corr \n Subject  (Intercept) 7.3912        \n          age         0.6943   -0.97\n Residual             1.3100        \nNumber of obs: 108, groups:  Subject, 27\nFixed Effects:\n(Intercept)    SexFemale  \n     24.517       -2.145  \n\n\n可以进一步使用survival包中的strata函数进行生存分析.\n\n\n代码\nlibrary(censored) # parsnip扩展包，主要用于删减回归和生存分析模型\n\nsurvival_reg() -&gt; parametric_spec\n\ndata(cancer, package = \"survival\")\n\nworkflow() |&gt;\n  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) |&gt;\n  add_model(parametric_spec, \n            formula = Surv(futime, fustat) ~ age + strata(rx)) -&gt; parametric_workflow\n\nparametric_workflow |&gt;\n  fit(data = ovarian) -&gt; parametric_fit\n\nparametric_fit\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: survival_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: c(fustat, futime)\nPredictors: c(age, rx)\n\n── Model ───────────────────────────────────────────────────────────────────────\nCall:\nsurvival::survreg(formula = Surv(futime, fustat) ~ age + strata(rx), \n    data = data, model = TRUE)\n\nCoefficients:\n(Intercept)         age \n 12.8734120  -0.1033569 \n\nScale:\n     rx=1      rx=2 \n0.7695509 0.4703602 \n\nLoglik(model)= -89.4   Loglik(intercept only)= -97.1\n    Chisq= 15.36 on 1 degrees of freedom, p= 8.88e-05 \nn= 26 \n\n\n\n\n\n2.7.5 同时创建多个workflow\n做预测模型时，一般需要评估多个不同的模型。例如筛选预测因子。可以创建一组formula来罗列不同的预测因子组合。\n\n\n代码\nlist(\n  longitude = Sale_Price ~ Longitude,\n  latitude = Sale_Price ~ Latitude,\n  coords = Sale_Price ~ Longitude + Latitude,\n  neighborhood = Sale_Price ~ Neighborhood) -&gt; location\n\n\n使用workflow_set()函数创建一个workflow集合。\n\n\n代码\nworkflow_set(preproc = location, models = list(lm = lm_model)) -&gt; location_models\n\nlocation_models\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 longitude_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 latitude_lm     &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 coords_lm       &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 neighborhood_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n代码\nlocation_models$info[[1]] # 查看第一个workflow的信息\n\n\n# A tibble: 1 × 4\n  workflow   preproc model      comment\n  &lt;list&gt;     &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n1 &lt;workflow&gt; formula linear_reg \"\"     \n\n\n代码\nextract_workflow(location_models, id = \"coords_lm\") # 提取一个workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude + Latitude\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n为每个formula创建fit对象：\n\n\n代码\nlocation_models |&gt;\n  mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train))) -&gt; location_models # 使用map函数对每个workflow进行拟合\n\nlocation_models\n\n\n# A workflow set/tibble: 4 × 5\n  wflow_id        info             option    result     fit       \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;     &lt;list&gt;    \n1 longitude_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n2 latitude_lm     &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n3 coords_lm       &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n4 neighborhood_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt; &lt;workflow&gt;\n\n\n代码\nlocation_models$fit[[1]] # 查看第一个workflow的拟合结果\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nSale_Price ~ Longitude\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude  \n    -176.46        -1.94  \n\n\n\n\n2.7.6 评估测试集\n使用last_fit函数，可以把模型拟合到整个训练集，然后评估测试集。\n\n\n代码\nlast_fit(lm_workflow, ames_split) -&gt; final_lm_res # 用法：last_fit(模型, 数据分割)\n\nfinal_lm_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [2342/588]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\n代码\nfinal_lm_res |&gt;\n  extract_workflow() # 提取workflow\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Variables\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nOutcomes: Sale_Price\nPredictors: c(Longitude, Latitude)\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)    Longitude     Latitude  \n   -300.251       -2.013        2.782  \n\n\n代码\nfinal_lm_res |&gt;\n  collect_metrics() # 收集模型评估指标\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.160 Preprocessor1_Model1\n2 rsq     standard       0.208 Preprocessor1_Model1\n\n\n代码\nfinal_lm_res |&gt;\n  collect_predictions() |&gt; # 收集预测结果\n  head()\n\n\n# A tibble: 6 × 5\n  id               .pred  .row Sale_Price .config             \n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;               \n1 train/test split  5.22     2       5.02 Preprocessor1_Model1\n2 train/test split  5.22     3       5.24 Preprocessor1_Model1\n3 train/test split  5.28     5       5.28 Preprocessor1_Model1\n4 train/test split  5.24    28       5.06 Preprocessor1_Model1\n5 train/test split  5.31    39       5.60 Preprocessor1_Model1\n6 train/test split  5.31    44       5.33 Preprocessor1_Model1",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#特征工程",
    "href": "chapters/tidymodels-基础.html#特征工程",
    "title": "2  tidymodels-基础",
    "section": "2.8 特征工程",
    "text": "2.8 特征工程\n特征工程指对预测值进行重新格式化，使其更容易被模型有效利用。特征工程的方法一般分为以下几种：\n\ndummy，哑变量，将分类变量分为多个哑变量（0-1变量）。\nzv， zero variance，删除方差为0的变量，也就是只有单一值的变量。\nimpute，估算，填补缺失值。\ndecorrelate，去相关，删除相关性较高的变量。一般使用PCA方法或者VIF方法。\nnormalize，标准化，将变量居中并缩放到单位方差。\ntransform，转换，将变量转换成更对称的分布。\n\n使用recipe包可以把不同的特征工程方法组合在一起，并应用到数据集上。\n\n2.8.1 创建特征工程\n从ames数据集中挑选以下预测因子：\n\nNeighborhood，分类变量，指房屋所在的社区，有29个水平。\nGr_Liv_Area，数值变量，指房屋的居住面积。\nYear_Built，数值变量，指房屋建造的年份。\nBldg_Type，分类变量，指房屋的类型，有5个水平，分别是OneFam，TwoFmCon，Duplex，Twnhs，TwnhsE。\n\n使用这些预测因子对Sale_Price进行预测，公式如下：\n\n\n代码\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, data = ames) # 由于Sale_Price取过对数，所以Gr_Liv_Area也取对数\n\n\n根据预测因子的性质和上述公式，使用recipe创建一个特征工程流程。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n       data = ames) |&gt; # 创建recipe对象，声明结果变量和预测因子\n  step_log(Gr_Liv_Area) |&gt; # 对Gr_Liv_Area取对数\n  step_dummy(all_nominal_predictors()) -&gt; simple_ames # 对分类变量创建哑变量\n\nsimple_ames\n\n\n\n\n\n\n\n\n提示\n\n\n\nall_nominal_predictors()函数用于选择所有的分类变量。\nall_numeric_predictors()函数用于选择所有的数值变量。\nall_predictors()函数用于选择所有的预测因子。\nall_outcomes()函数用于选择所有的结果变量。\nall_numeric()函数用于选择所有的数值变量。\n\n\n\n\n2.8.2 应用特征工程\n将特征工程simple_ames应用到workflowlm_workflow上。\n\n\n代码\nlm_workflow |&gt;\n  remove_variables() |&gt; # 删除所有的预测因子\n  remove_recipe() |&gt; # 删除所有的特征工程\n  add_recipe(simple_ames) -&gt; lm_workflow # 添加特征工程\n\nlm_workflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_log()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n代码\nfit(lm_workflow, ames_train) -&gt; lm_fit # 拟合模型\n\npredict(lm_fit, ames_test) |&gt; # 预测测试集\n  head()\n\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.17\n3  5.27\n4  5.08\n5  5.51\n6  5.44\n\n\n使用extract_*函数可以提取fit对象的不同信息，如模型参数、特征工程等。\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) # 提取特征工程，estimated = TRUE表示提取特征工程的估计值\n\nlm_fit |&gt;\n  extract_fit_parsnip() |&gt; # 提取模型参数\n  tidy() |&gt;\n  head()\n\n\n# A tibble: 6 × 5\n  term                       estimate std.error statistic   p.value\n  &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)                -0.682    0.228        -2.99 2.78e-  3\n2 Gr_Liv_Area                 0.271    0.00606      44.8  1.36e-315\n3 Year_Built                  0.00199  0.000115     17.3  6.19e- 63\n4 Neighborhood_College_Creek  0.0167   0.00807       2.06 3.91e-  2\n5 Neighborhood_Old_Town      -0.0357   0.00844      -4.22 2.50e-  5\n6 Neighborhood_Edwards       -0.0531   0.00755      -7.04 2.57e- 12\n\n\n\n\n2.8.3 其他特征工程示例\n\n2.8.3.1 定性变量的处理\n\n\n\n\n\n\n提示\n\n\n\nstep_unknown()函数用于将缺失值转化为专用因子水平。\nstep_novel()函数用于将未知的水平转化为新的水平。\nstep_other()函数用于将频率较低的多个水平合并为一个水平，频率阈值可以指定。\n\n\n上述函数可以用于处理定性变量的缺失值和未知水平，以及合并频率较低的水平，在此基础上，可以使用step_dummy()函数创建哑变量。\n\n\n2.8.3.2 交互项的处理\n交互项是指两个或多个变量的乘积，可以用于捕捉变量之间的关系。使用step_interact(~*:*)函数可以创建交互项。\n在ames数据集中，不同建筑类型的房屋可能与不同的居住面积存在交互，如 图 2.4 所示，可以使用交互项来捕捉这种关系。\n\n\n代码\nggplot(ames_train, aes(x = Gr_Liv_Area, y = 10^Sale_Price)) + \n  geom_point(alpha = .2) + \n  facet_wrap(~ Bldg_Type) + \n  geom_smooth(method = lm, formula = y ~ x, se = FALSE, color = \"lightblue\") + \n  scale_x_log10() + \n  scale_y_log10() + \n  labs(x = \"Gross Living Area\", y = \"Sale Price (USD)\")\n\n\n\n\n\n\n\n\n图 2.4: 五种不同类型建筑的总居住面积与销售价格的关系（log10变换后）\n\n\n\n\n\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) |&gt; # 创建recipe对象并声明结果变量和预测因子\n  step_log(Gr_Liv_Area, base = 10) |&gt; # 对Gr_Liv_Area取对数\n  step_other(Neighborhood, threshold = 0.01) |&gt; # 合并频率较低的水平\n  step_dummy(all_nominal_predictors()) |&gt; # 对分类变量创建哑变量\n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\")) -&gt; simple_ames # 创建交互项，其中:表示交互，可以使用+添加多组交互项\n\nsimple_ames\n\n\n\n\n\n\n\n\n警告\n\n\n\n一般来说，交互项需要在创建哑变量后才能创建，否则可能会报错。\n\n\n\n\n2.8.3.3 样条函数\n样条函数是一种非参数拟合方法，可以用于拟合非线性关系。使用step_ns()函数可以创建样条函数。\n在ames数据集中，经度和纬度可能与销售价格存在非线性关系，如 图 2.5 所示，可以使用样条函数来捕捉这种关系。\n\n\n代码\nlibrary(splines) # 样条函数\nlibrary(patchwork) # 绘图拼接\n\nplot_smoother &lt;- function(deg_free) { # 创建一个函数，用于绘制不同自由度的样条函数\n  ggplot(ames_train, aes(x = Latitude, y = 10^Sale_Price)) +  # 还原对数变换\n    geom_point(alpha = .2) +  # 添加散点图，alpha表示透明度\n    scale_y_log10() + # 对y轴进行对数变换\n    geom_smooth(\n      method = lm,\n      formula = y ~ ns(x, df = deg_free),\n      color = \"lightblue\",\n      se = FALSE\n    ) + # 添加样条函数，ns表示样条函数，df表示自由度\n    labs(title = paste(deg_free, \"Spline Terms\"),\n         y = \"Sale Price (USD)\")\n}\n\n( plot_smoother(2) + plot_smoother(5) ) / ( plot_smoother(20) + plot_smoother(100) ) # 绘制不同自由度的样条函数\n\n\n\n\n\n\n\n\n图 2.5: 销售价格与纬度的关系\n\n\n\n\n\n由 图 2.5 可以看出，自由度为5和20时，样条函数能较好地拟合数据，这里选择自由度为20的样条函数来捕捉纬度与销售价格的关系。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + Latitude,\n         data = ames_train) |&gt;\n  step_log(Gr_Liv_Area, base = 10) |&gt;\n  step_other(Neighborhood, threshold = 0.01) |&gt;\n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\") ) |&gt;\n  step_ns(Latitude, deg_free = 20) # 创建样条函数，自由度为20\n\n\n\n\n2.8.3.4 特征提取（PCA）\n特征提取是指将多个原始特征合并为少数几个新特征，以减少数据维度。使用step_pca()函数可以进行主成分分析（PCA）。\nPCA是一种线性提取方法，其优点是每个主成分之间互不相关，因此可以减少多重共线性的影响。但是，PCA的缺点是提取的特征不易解释，而且新特征可能与结果无关。\n在ames数据集中，有几个预测因子测量了房产的面积，如地下室总面积Total_Bsmt_SF、一楼面积First_Flr_SF、总居住面积Gr_Liv_Area等。PCA 可以将这些潜在的冗余变量表示为一个较小的特征集。除了总居住面积外，这些预测因子的名称中都有后缀SF（表示平方英尺）。\nPCA假定所有预测因子的单位相同，因此在使用PCA之前，最好使用step_normalize()对这些预测因子进行标准化。\n\n\n代码\nstep_normalize(matches(\"(SF$)|(Gr_Liv)\")) |&gt;\nstep_pca(matches(\"(SF$)|(Gr_Liv)\"))\n\n\n\n\n\n\n\n\n提示\n\n\n\n特征提取的其他方法还包括独立成分分析（ICA），非负矩阵分解（NMF），多维缩放（MDS），均匀流形近似（UMAP），t-分布邻域嵌入（t-SNE）等。\n\n\n\n\n2.8.3.5 抽样技术\n类别不平衡问题是指分类问题中不同类别的样本数量差异较大。在这种情况下，模型可能会偏向于预测样本数量较多的类别，而忽略样本数量较少的类别。针对类别不平衡问题，可以采用子采样技术，它通常不会提高整体性能，但可以生成表现更好的预测类概率分布。子采样技术分类如下：\n\n下抽样(Downsampling)：保留少数类样本，对多数类样本进行随机抽样，以平衡频率。\n扩大抽样(Upsampling)：合成新的少数类样本，或直接复制少数类样本，以平衡频率。\nHybrid：结合上述两种方法。\n\n在themis包中，step_downsample()和step_upsample()函数可以实现下抽样和扩大抽样。\n\n\n\n\n\n\n提示\n\n\n\nstep_filter()函数可以用于删除不需要的样本，如异常值、缺失值等。\nstep_sample()函数可以用于随机抽样。\nstep_slice()函数可以用于分割数据集。\nstep_arrange()函数可以用于排序数据集。\n\n\n\n\n2.8.3.6 一般变换\n一般变换是指对数据进行一般性的变换，如对数变换、幂变换、指数变换等。在recipes包中，step_log()、step_sqrt()、step_YeoJohnson()、step_boxcox()等函数可以实现对数变换、平方根变换、Yeo-Johnson变换、Box-Cox变换等。step_mutate()函数可以利用已有变量计算并创建新的变量。\n\n\n\n\n\n\n警告\n\n\n\n进行一般变换是，需要格外注意避免数据泄露。转换应该在拆分数据集之前进行。\n\n\n\n\n2.8.3.7 自然语言处理\n自然语言处理（NLP）是指对文本数据进行处理，如分词、词干提取、词形还原、停用词过滤、词频统计、TF-IDF计算等。\ntextrecipes包是recipes包的扩展，提供了一系列用于文本数据处理的函数。step_tokenize()、step_stem()、step_lemma()、step_stopwords()、step_tf()、step_tfidf()等函数可以实现分词、词干提取、词形还原、停用词过滤、词频统计、TF-IDF计算等。可以在Cookbook - Using more complex recipes involving text中参考相关函数的使用方法。但是，textrecipes包目前还不支持中文文本的处理，可能需要使用jiebaR包（jiebaR 中文分词文档）等其他包来处理中文文本。\n\n\n\n2.8.4 tidy\n首先，为ames数据集创建一个recipe对象。然后，使用tidy()函数查看recipe对象的内容摘要。\nid参数可以用于指定recipe步骤函数的标识符。在多次添加相同的步骤函数时，可以使用id参数来区分这些步骤函数。\n\n\n代码\nrecipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n         Latitude + Longitude, data = ames_train) |&gt;\n  step_log(Gr_Liv_Area, base = 10) |&gt;\n  step_other(Neighborhood, threshold = 0.01, id = \"my_id\") |&gt; # 指定id参数\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\")) |&gt;\n  step_ns(Latitude, Longitude, deg_free = 20) -&gt; ames_recipe\n\names_recipe |&gt;\n  tidy()\n\n\n# A tibble: 5 × 6\n  number operation type     trained skip  id            \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;    &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;         \n1      1 step      log      FALSE   FALSE log_yQoQt     \n2      2 step      other    FALSE   FALSE my_id         \n3      3 step      dummy    FALSE   FALSE dummy_EvyKp   \n4      4 step      interact FALSE   FALSE interact_VANTp\n5      5 step      ns       FALSE   FALSE ns_J20uP      \n\n\n使用ames_recipe对象建立workflow：\n\n\n代码\nworkflow() |&gt;\n  add_model(lm_model) |&gt;\n  add_recipe(ames_recipe) -&gt; lm_workflow\n\nlm_workflow |&gt;\n  fit(data = ames_train) -&gt; lm_fit\n\n\n可以使用tidy()函数并指定id参数，查看对应id步骤的结果，也可以指定number参数，查看对应的结果：\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) |&gt;\n  tidy(id = \"my_id\")\n\n\n# A tibble: 21 × 3\n   terms        retained           id   \n   &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;\n 1 Neighborhood North_Ames         my_id\n 2 Neighborhood College_Creek      my_id\n 3 Neighborhood Old_Town           my_id\n 4 Neighborhood Edwards            my_id\n 5 Neighborhood Somerset           my_id\n 6 Neighborhood Northridge_Heights my_id\n 7 Neighborhood Gilbert            my_id\n 8 Neighborhood Sawyer             my_id\n 9 Neighborhood Northwest_Ames     my_id\n10 Neighborhood Sawyer_West        my_id\n# ℹ 11 more rows\n\n\n代码\nlm_fit |&gt;\n  extract_recipe(estimated = TRUE) |&gt;\n  tidy(number = 3)\n\n\n# A tibble: 25 × 3\n   terms        columns            id         \n   &lt;chr&gt;        &lt;chr&gt;              &lt;chr&gt;      \n 1 Neighborhood College_Creek      dummy_EvyKp\n 2 Neighborhood Old_Town           dummy_EvyKp\n 3 Neighborhood Edwards            dummy_EvyKp\n 4 Neighborhood Somerset           dummy_EvyKp\n 5 Neighborhood Northridge_Heights dummy_EvyKp\n 6 Neighborhood Gilbert            dummy_EvyKp\n 7 Neighborhood Sawyer             dummy_EvyKp\n 8 Neighborhood Northwest_Ames     dummy_EvyKp\n 9 Neighborhood Sawyer_West        dummy_EvyKp\n10 Neighborhood Mitchell           dummy_EvyKp\n# ℹ 15 more rows\n\n\n\n\n2.8.5 “roles”变量\n有一部分变量，既不是预测变量，也不是因子变量，但在数据集中可能起到建模之外的作用。可以使用add_role(), remove_role()和update_role()函数来指定这些变量的角色。同时，可以为step_*()函数指定roles参数，不过大部分step_*()函数都会自动给定变量的角色。\n代码示例：\n\n\n代码\names_recipe |&gt;\n  update_role(address, new_role = \"street address\") # 对于已建好的recipe对象，使用update_role()函数来更新变量的角色，在构建recipe对象时，应使用add_role()函数。",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  },
  {
    "objectID": "chapters/tidymodels-基础.html#模型性能评估",
    "href": "chapters/tidymodels-基础.html#模型性能评估",
    "title": "2  tidymodels-基础",
    "section": "2.9 模型性能评估",
    "text": "2.9 模型性能评估\n\n\n\n\n\n\n重要\n\n\n\n重采样方法是最有效的验证方法。\n\n\nyardstick包是tidymodels核心包之一，可以用于模型性能评估。按结果变量的类型，即数值变量、二分类变量和多分类变量，模型性能评估的指标也有所不同。\n\n2.9.1 数值变量-回归模型\names数据集的预测模型lm_fit包含了回归模型和预测集，同时有交互作用和经纬度样条函数。首先，使用predict()函数计算预测值。\n\n\n代码\nlm_fit |&gt;\n  predict(new_data = ames_test |&gt;\n            select(-Sale_Price)) -&gt; ames_test_results\n\names_test_results |&gt;\n  head()\n\n\n# A tibble: 6 × 1\n  .pred\n  &lt;dbl&gt;\n1  5.07\n2  5.17\n3  5.28\n4  5.05\n5  5.51\n6  5.42\n\n\n将预测值和实际值放在一起，使用bind_cols()函数：\n\n\n代码\names_test_results |&gt;\n  bind_cols(ames_test |&gt;\n              select(Sale_Price)) -&gt; ames_test_results\n\names_test_results |&gt;\n  head()\n\n\n# A tibble: 6 × 2\n  .pred Sale_Price\n  &lt;dbl&gt;      &lt;dbl&gt;\n1  5.07       5.02\n2  5.17       5.24\n3  5.28       5.28\n4  5.05       5.06\n5  5.51       5.60\n6  5.42       5.33\n\n\n首先，作图查看预测值和实际值的关系：\n\n\n代码\nggplot(ames_test_results, aes(x = Sale_Price, y = .pred)) + \n  geom_abline(lty = 2) + # 添加对角线\n  geom_point(alpha = 0.5) + \n  labs(y = \"Predicted Sale Price (log10)\", x = \"Sale Price (log10)\") +\n  coord_obs_pred() # 使x轴和y轴的刻度一致\n\n\n\n\n\n\n\n\n图 2.6: 预测值和实际值的关系(log10)\n\n\n\n\n\n由 图 2.6 发现，有几个预测值和实际值的偏差较大。使用rmse()函数计算均方根误差，rsq函数计算R^2，mae函数计算平均绝对误差。\n\n\n代码\names_test_results |&gt;\n  rmse(truth = Sale_Price, estimate = .pred) # 计算单一指标\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      0.0754\n\n\n代码\names_metrics &lt;- metric_set(rmse, rsq, mae) # 创建指标集\n\names_test_results |&gt;\n  ames_metrics(truth = Sale_Price, estimate = .pred) # 同时计算多个指标\n\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      0.0754\n2 rsq     standard      0.826 \n3 mae     standard      0.0546\n\n\n\n\n2.9.2 二分类变量-logistic回归模型\n使用modeldata包（tidymodels核心包之一）中的two_class_example数据集，这是一个模拟了logistic回归模型预测结果的数据集。\n\n\n代码\ndata(two_class_example, package = \"modeldata\")\ntibble(two_class_example) |&gt;\n  head()\n\n\n# A tibble: 6 × 4\n  truth   Class1   Class2 predicted\n  &lt;fct&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    \n1 Class2 0.00359 0.996    Class2   \n2 Class1 0.679   0.321    Class1   \n3 Class2 0.111   0.889    Class2   \n4 Class1 0.735   0.265    Class1   \n5 Class2 0.0162  0.984    Class2   \n6 Class1 0.999   0.000725 Class1   \n\n\n对于logistic回归模型，模型性能评估指标有很多，列举如下：\n\nconf_mat：混淆矩阵\n\n\n\n代码\ntwo_class_example |&gt;\n  conf_mat(truth = truth, estimate = predicted)\n\n\n          Truth\nPrediction Class1 Class2\n    Class1    227     50\n    Class2     31    192\n\n\n\naccuracy：准确率\n\n\n\n代码\ntwo_class_example |&gt;\n  accuracy(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.838\n\n\n\nmcc：Matthews相关系数\n\n\n\n代码\ntwo_class_example |&gt;\n  mcc(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 mcc     binary         0.677\n\n\n\nf_meas：F1值，精确率和召回率的调和平均数\n\n\n\n代码\ntwo_class_example |&gt;\n  f_meas(truth = truth, estimate = predicted)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 f_meas  binary         0.849\n\n\n\nroc_curve和roc_auc：ROC曲线和AUC\n\n\n\n代码\ntwo_class_example |&gt;\n  roc_curve(truth = truth, Class1) -&gt; two_class_curve\n\ntwo_class_curve\n\n\n# A tibble: 502 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 -Inf           0                 1\n 2    1.79e-7     0                 1\n 3    4.50e-6     0.00413           1\n 4    5.81e-6     0.00826           1\n 5    5.92e-6     0.0124            1\n 6    1.22e-5     0.0165            1\n 7    1.40e-5     0.0207            1\n 8    1.43e-5     0.0248            1\n 9    2.38e-5     0.0289            1\n10    3.30e-5     0.0331            1\n# ℹ 492 more rows\n\n\n代码\ntwo_class_example |&gt;\n  roc_auc(truth = truth, Class1)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.939\n\n\n\n\n代码\ntwo_class_curve |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n图 2.7: ROC曲线\n\n\n\n\n\n\n\n2.9.3 多分类变量-多分类模型\n\n\n代码\ndata(hpc_cv)\ntibble(hpc_cv) |&gt;\n  head()\n\n\n# A tibble: 6 × 7\n  obs   pred     VF      F       M          L Resample\n  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   \n1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01  \n2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01  \n3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01  \n4 VF    VF    0.929 0.0653 0.00579 0.0000156  Fold01  \n5 VF    VF    0.942 0.0543 0.00381 0.00000729 Fold01  \n6 VF    VF    0.951 0.0462 0.00272 0.00000384 Fold01  \n\n\n对于多分类模型，使用离散类预测的指标函数与二进制指标函数相同，如accuracy, mcc, f_meas等。\n其他指标函数包括：\n\nsensitivity：灵敏度，需要用estimator参数指定函数\n\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"macro\") # macro表示宏平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 sensitivity macro          0.560\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"micro\") # micro表示微平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 sensitivity micro          0.709\n\n\n代码\nhpc_cv |&gt;\n  sensitivity(truth = obs, estimate = pred, estimator = \"macro_weighted\") # macro_weighted表示加权宏平均\n\n\n# A tibble: 1 × 3\n  .metric     .estimator     .estimate\n  &lt;chr&gt;       &lt;chr&gt;              &lt;dbl&gt;\n1 sensitivity macro_weighted     0.709\n\n\n\nroc_auc：多分类模型的AUC，必须向函数提供所有的类别概率列\n\n\n\n代码\nhpc_cv |&gt;\n  roc_auc(truth = obs, VF, F, M, L) # 这里也可以指定estimator参数\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.829\n\n\nhpc_cv数据集中，有Resample列，是交叉验证的分组。可以利用group_by()函数为每个分组计算指标或作图，如 图 2.8 所示。\n\n\n代码\nhpc_cv |&gt;\n  group_by(Resample) |&gt;\n  roc_curve(obs, VF, F, M, L) |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n图 2.8: 分组ROC曲线\n\n\n\n\n\n\n\n\n\n\n图 2.1: 销售价格（美元）\n图 2.2: 对数变换后的销售价格（美元）\n图 2.3: 房屋销售价格分布(log)，虚线代表四分位数\n图 2.4: 五种不同类型建筑的总居住面积与销售价格的关系（log10变换后）\n图 2.5: 销售价格与纬度的关系\n图 2.6: 预测值和实际值的关系(log10)\n图 2.7: ROC曲线\n图 2.8: 分组ROC曲线",
    "crumbs": [
      "tidymodels",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>tidymodels-基础</span>"
    ]
  }
]